
@article{zhaoPyODPythonToolbox2019,
	title = {{PyOD}: {A} {Python} {Toolbox} for {Scalable} {Outlier} {Detection}},
	shorttitle = {{PyOD}},
	url = {http://arxiv.org/abs/1901.01588},
	abstract = {PyOD is an open-source Python toolbox for performing scalable outlier detection on multivariate data. Uniquely, it provides access to a wide range of outlier detection algorithms, including established outlier ensembles and more recent neural network-based approaches, under a single, well-documented API designed for use by both practitioners and researchers. With robustness and scalability in mind, best practices such as unit testing, continuous integration, code coverage, maintainability checks, interactive examples and parallelization are emphasized as core components in the toolbox's development. PyOD is compatible with both Python 2 and 3 and can be installed through Python Package Index (PyPI) or https://github.com/yzhao062/pyod.},
	urldate = {2019-01-30},
	journal = {arXiv:1901.01588 [cs, stat]},
	author = {Zhao, Yue and Nasrullah, Zain and Li, Zheng},
	month = jan,
	year = {2019},
	note = {arXiv: 1901.01588},
	keywords = {Computer Science - Information Retrieval, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {2019-Zhao-PyOD.pdf:/home/migue/Zotero/storage/5474BDIA/2019-Zhao-PyOD.pdf:application/pdf}
}

@book{aggarwalOutlierEnsemblesIntroduction2017,
	title = {Outlier {Ensembles}: {An} {Introduction}},
	isbn = {978-3-319-54765-7},
	shorttitle = {Outlier {Ensembles}},
	abstract = {This book discusses a variety of methods for outlier ensembles and organizes them by the specific principles with which accuracy improvements are achieved. In addition, it covers the techniques with which such methods can be made more effective. A formal classification of these methods is provided, and the circumstances in which they work well are examined. The authors cover how outlier ensembles relate (both theoretically and practically) to the ensemble techniques used commonly for other data mining problems like classification. The similarities and (subtle) differences in the ensemble techniques for the classification and outlier detection problems are explored. These subtle differences do impact the design of ensemble algorithms for the latter problem. This book can be used for courses in data mining and related curricula. Many illustrative examples and exercises are provided in order to facilitate classroom teaching. A familiarity is assumed to the outlier detection problem and also to generic problem of ensemble analysis in classification. This is because many of the ensemble methods discussed in this book are adaptations from their counterparts in the classification domain. Some techniques explained in this book, such as wagging, randomized feature weighting, and geometric subsampling, provide new insights that are not available elsewhere. Also included is an analysis of the performance of various types of base detectors and their relative effectiveness. The book is valuable for researchers and practitioners for leveraging ensemble methods into optimal algorithmic design.},
	language = {en},
	publisher = {Springer},
	author = {Aggarwal, Charu C. and Sathe, Saket},
	month = apr,
	year = {2017},
	note = {Google-Books-ID: UNmfDgAAQBAJ},
	keywords = {Computers / Information Technology, Computers / Intelligence (AI) \& Semantics, Computers / Mathematical \& Statistical Software, Computers / Networking / General, Computers / Online Services},
	file = {2017-Aggarwal-Outlier_Ensembles.pdf:/home/migue/Zotero/storage/9K9GE5JA/2017-Aggarwal-Outlier_Ensembles.pdf:application/pdf}
}

@book{aggarwalOutlierAnalysis2017,
	address = {New York},
	title = {Outlier {Analysis}},
	isbn = {978-1-4614-6395-5},
	url = {//www.springer.com/us/book/9781461463955},
	abstract = {With the increasing advances in hardware technology for data collection, and advances in software technology (databases) for data organization, computer scientists have increasingly participated in the latest advancements of the outlier analysis field. Computer scientists, specifically, approach this field based on their practical experiences in managing large amounts of data, and with far fewer assumptions– the data can be of any type, structured or unstructured, and may be extremely large. Outlier Analysis is a comprehensive exposition, as understood by data mining experts, statisticians and computer scientists. The book has been organized carefully, and emphasis was placed on simplifying the content, so that students and practitioners can also benefit. Chapters will typically cover one of three areas: methods and techniques commonly used in outlier analysis, such as linear methods, proximity-based methods, subspace methods, and supervised methods; data domains, such as, text, categorical, mixed-attribute, time-series, streaming, discrete sequence, spatial and network data; and key applications of these methods as applied to diverse domains such as credit card fraud detection, intrusion detection, medical diagnosis, earth science, web log analytics, and social network analysis are covered.},
	language = {en},
	urldate = {2018-03-20},
	publisher = {Springer-Verlag},
	author = {Aggarwal, Charu C.},
	year = {2017},
	file = {2017-Aggarwal-Outlier_Analysis.pdf:/home/migue/Zotero/storage/FNU7VTSS/2017-Aggarwal-Outlier_Analysis.pdf:application/pdf}
}

@inproceedings{papadimitriouLOCIFastOutlier2003,
	title = {{LOCI}: fast outlier detection using the local correlation integral},
	shorttitle = {{LOCI}},
	doi = {10.1109/ICDE.2003.1260802},
	abstract = {Outlier detection is an integral part of data mining and has attracted much attention recently [M. Breunig et al., (2000)], [W. Jin et al., (2001)], [E. Knorr et al., (2000)]. We propose a new method for evaluating outlierness, which we call the local correlation integral (LOCI). As with the best previous methods, LOCI is highly effective for detecting outliers and groups of outliers (a.k.a. micro-clusters). In addition, it offers the following advantages and novelties: (a) It provides an automatic, data-dictated cutoff to determine whether a point is an outlier-in contrast, previous methods force users to pick cut-offs, without any hints as to what cut-off value is best for a given dataset. (b) It can provide a LOCI plot for each point; this plot summarizes a wealth of information about the data in the vicinity of the point, determining clusters, micro-clusters, their diameters and their inter-cluster distances. None of the existing outlier-detection methods can match this feature, because they output only a single number for each point: its outlierness score, (c) Our LOCI method can be computed as quickly as the best previous methods, (d) Moreover, LOCI leads to a practically linear approximate method, aLOCI (for approximate LOCI), which provides fast highly-accurate outlier detection. To the best of our knowledge, this is the first work to use approximate computations to speed up outlier detection. Experiments on synthetic and real world data sets show that LOCI and aLOCI can automatically detect outliers and micro-clusters, without user-required cut-offs, and that they quickly spot both expected and unexpected outliers.},
	booktitle = {Proceedings 19th {International} {Conference} on {Data} {Engineering} ({Cat}. {No}.03CH37405)},
	author = {Papadimitriou, S. and Kitagawa, H. and Gibbons, P. B. and Faloutsos, C.},
	month = mar,
	year = {2003},
	keywords = {aLOCI, approximate LOCI, approximation theory, correlation theory, Data engineering, data mining, inter-cluster distance, linear approximate method, local correlation integral, LOCI, micro-cluster, outlier detection, real world data set, statistical analysis, synthetic data set, very large databases},
	pages = {315--326},
	file = {2003-Papadimitriou-LOCI.pdf:/home/migue/Zotero/storage/P8KBQLQK/2003-Papadimitriou-LOCI.pdf:application/pdf;IEEE Xplore Abstract Record:/home/migue/Zotero/storage/QUJ42ENM/1260802.html:text/html}
}

@inproceedings{steinLocalSubspacebasedOutlier2016,
	title = {Local subspace-based outlier detection using global neighbourhoods},
	doi = {10.1109/BigData.2016.7840717},
	abstract = {Outlier detection in high-dimensional data is a challenging yet important task, as it has applications in, e.g., fraud detection and quality control. State-of-the-art density-based algorithms perform well because they 1) take the local neighbourhoods of data points into account and 2) consider feature subspaces. In highly complex and high-dimensional data, however, existing methods are likely to overlook important outliers because they do not explicitly take into account that the data is often a mixture distribution of multiple components. We therefore introduce GLOSS, an algorithm that performs local subspace outlier detection using global neighbourhoods. Experiments on synthetic data demonstrate that GLOSS more accurately detects local outliers in mixed data than its competitors. Moreover, experiments on real-world data show that our approach identifies relevant outliers overlooked by existing methods, confirming that one should keep an eye on the global perspective even when doing local outlier detection.},
	booktitle = {2016 {IEEE} {International} {Conference} on {Big} {Data} ({Big} {Data})},
	author = {Stein, B. van and Leeuwen, M. van and Bäck, T.},
	month = dec,
	year = {2016},
	note = {00000},
	keywords = {Big data, Clustering algorithms, data handling, data points, density-based algorithms, Detection algorithms, Feature extraction, feature subspaces, global neighbourhoods, GLOSS algorithm, high-dimensional data, local subspace-based outlier detection, Probabilistic logic, Standards, Two dimensional displays},
	pages = {1136--1142},
	file = {IEEE Xplore Abstract Record:/home/migue/Zotero/storage/GSUZ4WVT/7840717.html:text/html}
}

@inproceedings{kriegelLoOPLocalOutlier2009,
	address = {New York, NY, USA},
	series = {{CIKM} '09},
	title = {{LoOP}: {Local} {Outlier} {Probabilities}},
	isbn = {978-1-60558-512-3},
	shorttitle = {{LoOP}},
	url = {http://doi.acm.org/10.1145/1645953.1646195},
	doi = {10.1145/1645953.1646195},
	abstract = {Many outlier detection methods do not merely provide the decision for a single data object being or not being an outlier but give also an outlier score or "outlier factor" signaling "how much" the respective data object is an outlier. A major problem for any user not very acquainted with the outlier detection method in question is how to interpret this "factor" in order to decide for the numeric score again whether or not the data object indeed is an outlier. Here, we formulate a local density based outlier detection method providing an outlier "score" in the range of [0, 1] that is directly interpretable as a probability of a data object for being an outlier.},
	urldate = {2019-05-02},
	booktitle = {Proceedings of the 18th {ACM} {Conference} on {Information} and {Knowledge} {Management}},
	publisher = {ACM},
	author = {Kriegel, Hans-Peter and Kröger, Peer and Schubert, Erich and Zimek, Arthur},
	year = {2009},
	note = {00000 
event-place: Hong Kong, China},
	keywords = {detection, outlier},
	pages = {1649--1652},
	file = {2009-Kriegel-LoOP.pdf:/home/migue/Zotero/storage/CNKJ48P9/2009-Kriegel-LoOP.pdf:application/pdf}
}

@inproceedings{wangDistanceBasedOutlierDetection2009,
	title = {Distance-{Based} {Outlier} {Detection} on {Uncertain} {Data}},
	volume = {1},
	doi = {10.1109/CIT.2009.107},
	abstract = {The technique of outlier detection is useful in many real world applications such as detection of network intrusion. It has been studied intensively on deterministic data. However, it is still a novel research field on uncertain data. To our best knowledge, this paper is the first one to focus on distance-based outlier detection on uncertain data, in which each data is affiliated with a certain confidence value. In this paper, we propose a new definition of outlier on uncertain data. Based on the properties we discovered, both dynamic programming approach (DPA) and grid-based pruning approach (GPA) are used for detecting outliers on uncertain data efficiently. Detailed analysis and thorough experimental results demonstrate the efficiency and scalability of our method.},
	booktitle = {2009 {Ninth} {IEEE} {International} {Conference} on {Computer} and {Information} {Technology}},
	author = {Wang, B. and Xiao, G. and Yu, H. and Yang, X.},
	month = oct,
	year = {2009},
	note = {00059},
	keywords = {Data engineering, outlier, Algorithm design and analysis, distance, distance-based outlier detection, dynamic programming, dynamic programming approach, efficiency, grid-based pruning approach, Information science, Information technology, Interference, Intrusion detection, Monitoring, network intrusion, security of data, Sensor phenomena and characterization, uncertain, uncertain data, Uncertainty, Wireless sensor networks},
	pages = {293--298},
	file = {2009-Wang-Distance-Based_Outlier_Detection_on_Uncertain_Data.pdf:/home/migue/Zotero/storage/TWKFT59L/2009-Wang-Distance-Based_Outlier_Detection_on_Uncertain_Data.pdf:application/pdf;IEEE Xplore Abstract Record:/home/migue/Zotero/storage/AMGTCRKI/5328004.html:text/html;IEEE Xplore Abstract Record:/home/migue/Zotero/storage/WVXBU9FP/5328004.html:text/html}
}

@article{cipolliniConditionbasedMaintenanceNaval2018,
	title = {Condition-based maintenance of naval propulsion systems: {Data} analysis with minimal feedback},
	volume = {177},
	issn = {0951-8320},
	shorttitle = {Condition-based maintenance of naval propulsion systems},
	url = {http://www.sciencedirect.com/science/article/pii/S0951832017309973},
	doi = {10.1016/j.ress.2018.04.015},
	abstract = {The maintenance of the several components of a Ship Propulsion Systems is an onerous activity, which need to be efficiently programmed by a shipbuilding company in order to save time and money. The replacement policies of these components can be planned in a Condition-Based fashion, by predicting their decay state and thus proceed to substitution only when really needed. In this paper, authors propose several Data Analysis supervised and unsupervised techniques for the Condition-Based Maintenance of a vessel, characterised by a combined diesel-electric and gas propulsion plant. In particular, this analysis considers a scenario where the collection of vast amounts of labelled data containing the decay state of the components is unfeasible. In fact, the collection of labelled data requires a drydocking of the ship and the intervention of expert operators, which is usually an infrequent event. As a result, authors focus on methods which could allow only a minimal feedback from naval specialists, thus simplifying the dataset collection phase. Confidentiality constraints with the Navy require authors to use a real-data validated simulator and the dataset has been published for free use through the OpenML repository.},
	urldate = {2019-04-23},
	journal = {Reliability Engineering \& System Safety},
	author = {Cipollini, Francesca and Oneto, Luca and Coraddu, Andrea and Murphy, Alan John and Anguita, Davide},
	month = sep,
	year = {2018},
	note = {00005},
	keywords = {Condition-based maintenance, Data analysis, Minimal feedback., Naval propulsion systems, Novelty detection, Supervised learning, Unsupervised learning},
	pages = {12--23},
	file = {2018-Cipollini-Condition-based_maintenance_of_naval_propulsion_systems.pdf:/home/migue/Zotero/storage/6P7CSN53/2018-Cipollini-Condition-based_maintenance_of_naval_propulsion_systems.pdf:application/pdf;ScienceDirect Snapshot:/home/migue/Zotero/storage/69NHS8T2/S0951832017309973.html:text/html}
}

@article{yuFindoutFindingOutliers2002,
	title = {Findout: finding outliers in very large datasets},
	volume = {4},
	shorttitle = {Findout},
	number = {4},
	journal = {Knowledge and Information Systems},
	author = {Yu, Dantong and Sheikholeslami, Gholamhosein and Zhang, Aidong},
	year = {2002},
	note = {00234},
	keywords = {Keywords: Clustering; Data mining; Outliers; Wavelet},
	pages = {387--412},
	file = {2002-Yu-Findout.pdf:/home/migue/Zotero/storage/A4LEIMUH/2002-Yu-Findout.pdf:application/pdf}
}

@article{kimRobustKernelDensity2012,
	title = {Robust {Kernel} {Density} {Estimation}},
	volume = {13},
	issn = {ISSN 1533-7928},
	url = {http://www.jmlr.org/papers/v13/kim12b.html},
	number = {Sep},
	urldate = {2019-03-15},
	journal = {Journal of Machine Learning Research},
	author = {Kim, JooSeuk and Scott, Clayton D.},
	year = {2012},
	note = {00000},
	pages = {2529--2565},
	file = {2012-Kim-Robust_Kernel_Density_Estimation.pdf:/home/migue/Zotero/storage/P22L8PGQ/2012-Kim-Robust_Kernel_Density_Estimation.pdf:application/pdf;Snapshot:/home/migue/Zotero/storage/CP96ZZ8C/kim12b.html:text/html}
}

@article{emmottMetaAnalysisAnomalyDetection2015,
	title = {A {Meta}-{Analysis} of the {Anomaly} {Detection} {Problem}},
	url = {http://arxiv.org/abs/1503.01158},
	abstract = {This article provides a thorough meta-analysis of the anomaly detection problem. To accomplish this we first identify approaches to benchmarking anomaly detection algorithms across the literature and produce a large corpus of anomaly detection benchmarks that vary in their construction across several dimensions we deem important to real-world applications: (a) point difficulty, (b) relative frequency of anomalies, (c) clusteredness of anomalies, and (d) relevance of features. We apply a representative set of anomaly detection algorithms to this corpus, yielding a very large collection of experimental results. We analyze these results to understand many phenomena observed in previous work. First we observe the effects of experimental design on experimental results. Second, results are evaluated with two metrics, ROC Area Under the Curve and Average Precision. We employ statistical hypothesis testing to demonstrate the value (or lack thereof) of our benchmarks. We then offer several approaches to summarizing our experimental results, drawing several conclusions about the impact of our methodology as well as the strengths and weaknesses of some algorithms. Last, we compare results against a trivial solution as an alternate means of normalizing the reported performance of algorithms. The intended contributions of this article are many; in addition to providing a large publicly-available corpus of anomaly detection benchmarks, we provide an ontology for describing anomaly detection contexts, a methodology for controlling various aspects of benchmark creation, guidelines for future experimental design and a discussion of the many potential pitfalls of trying to measure success in this field.},
	urldate = {2019-03-15},
	journal = {arXiv:1503.01158 [cs, stat]},
	author = {Emmott, Andrew and Das, Shubhomoy and Dietterich, Thomas and Fern, Alan and Wong, Weng-Keen},
	month = mar,
	year = {2015},
	note = {00000 
arXiv: 1503.01158},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
	file = {2015-Emmott-A_Meta-Analysis_of_the_Anomaly_Detection_Problem.pdf:/home/migue/Zotero/storage/KPQS5BX6/2015-Emmott-A_Meta-Analysis_of_the_Anomaly_Detection_Problem.pdf:application/pdf;arXiv.org Snapshot:/home/migue/Zotero/storage/3ALKSUHV/1503.html:text/html}
}

@incollection{schubertGeneralizedOutlierDetection2014,
	series = {Proceedings},
	title = {Generalized {Outlier} {Detection} with {Flexible} {Kernel} {Density} {Estimates}},
	url = {https://epubs.siam.org/doi/abs/10.1137/1.9781611973440.63},
	abstract = {We analyse the interplay of density estimation and outlier detection in density-based outlier detection. By clear and principled decoupling of both steps, we formulate a generalization of density-based outlier detection methods based on kernel density estimation. Embedded in a broader framework for outlier detection, the resulting method can be easily adapted to detect novel types of outliers: while common outlier detection methods are designed for detecting objects in sparse areas of the data set, our method can be modified to also detect unusual local concentrations or trends in the data set if desired. It allows for the integration of domain knowledge and specific requirements. We demonstrate the flexible applicability and scalability of the method on large real world data sets.},
	urldate = {2019-03-15},
	booktitle = {Proceedings of the 2014 {SIAM} {International} {Conference} on {Data} {Mining}},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Schubert, E. and Zimek, A. and Kriegel, H.},
	month = apr,
	year = {2014},
	doi = {10.1137/1.9781611973440.63},
	note = {00000 },
	pages = {542--550},
	file = {2014-Schubert-Generalized_Outlier_Detection_with_Flexible_Kernel_Density_Estimates.pdf:/home/migue/Zotero/storage/CMVBDZVG/2014-Schubert-Generalized_Outlier_Detection_with_Flexible_Kernel_Density_Estimates.pdf:application/pdf;Snapshot:/home/migue/Zotero/storage/DUITKHD2/1.9781611973440.html:text/html}
}

@inproceedings{lateckiOutlierDetectionKernel2007,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Outlier {Detection} with {Kernel} {Density} {Functions}},
	isbn = {978-3-540-73499-4},
	abstract = {Outlier detection has recently become an important problem in many industrial and financial applications. In this paper, a novel unsupervised algorithm for outlier detection with a solid statistical foundation is proposed. First we modify a nonparametric density estimate with a variable kernel to yield a robust local density estimation. Outliers are then detected by comparing the local density of each point to the local density of its neighbors. Our experiments performed on several simulated data sets have demonstrated that the proposed approach can outperform two widely used outlier detection algorithms (LOF and LOCI).},
	language = {en},
	booktitle = {Machine {Learning} and {Data} {Mining} in {Pattern} {Recognition}},
	publisher = {Springer Berlin Heidelberg},
	author = {Latecki, Longin Jan and Lazarevic, Aleksandar and Pokrajac, Dragoljub},
	editor = {Perner, Petra},
	year = {2007},
	note = {00000},
	keywords = {False Alarm Rate, Local Density Estimate, Neighbor Query, Outlier Detection, Variable Kernel},
	pages = {61--75},
	file = {2007-Latecki-Outlier_Detection_with_Kernel_Density_Functions.pdf:/home/migue/Zotero/storage/6XS6498E/2007-Latecki-Outlier_Detection_with_Kernel_Density_Functions.pdf:application/pdf}
}

@article{hidoStatisticalOutlierDetection2011,
	title = {Statistical outlier detection using direct density ratio estimation},
	volume = {26},
	issn = {0219-3116},
	url = {https://doi.org/10.1007/s10115-010-0283-2},
	doi = {10.1007/s10115-010-0283-2},
	abstract = {We propose a new statistical approach to the problem of inlier-based outlier detection, i.e., finding outliers in the test set based on the training set consisting only of inliers. Our key idea is to use the ratio of training and test data densities as an outlier score. This approach is expected to have better performance even in high-dimensional problems since methods for directly estimating the density ratio without going through density estimation are available. Among various density ratio estimation methods, we employ the method called unconstrained least-squares importance fitting (uLSIF) since it is equipped with natural cross-validation procedures, allowing us to objectively optimize the value of tuning parameters such as the regularization parameter and the kernel width. Furthermore, uLSIF offers a closed-form solution as well as a closed-form formula for the leave-one-out error, so it is computationally very efficient and is scalable to massive datasets. Simulations with benchmark and real-world datasets illustrate the usefulness of the proposed approach.},
	language = {en},
	number = {2},
	urldate = {2019-03-15},
	journal = {Knowl Inf Syst},
	author = {Hido, Shohei and Tsuboi, Yuta and Kashima, Hisashi and Sugiyama, Masashi and Kanamori, Takafumi},
	month = feb,
	year = {2011},
	note = {00000},
	keywords = {Density ratio, Importance, Outlier detection, Unconstrained least-squares importance fitting (uLSIF)},
	pages = {309--336},
	file = {2011-Hido-Statistical_outlier_detection_using_direct_density_ratio_estimation.pdf:/home/migue/Zotero/storage/DTXPBSK6/2011-Hido-Statistical_outlier_detection_using_direct_density_ratio_estimation.pdf:application/pdf}
}

@inproceedings{satheSubspaceOutlierDetection2016,
	title = {Subspace {Outlier} {Detection} in {Linear} {Time} with {Randomized} {Hashing}},
	doi = {10.1109/ICDM.2016.0057},
	abstract = {Outlier detection algorithms are often computationally intensive because of their need to score each point in the data. Even simple distance-based algorithms have quadratic complexity. High-dimensional outlier detection algorithms such as subspace methods are often even more computationally intensive because of their need to explore different subspaces of the data. In this paper, we propose an exceedingly simple subspace outlier detection algorithm, which can be implemented in a few lines of code, and whose complexity is linear in the size of the data set and the space requirement is constant. We show that this outlier detection algorithm is much faster than both conventional and high-dimensional algorithms and also provides more accurate results. The approach uses randomized hashing to score data points and has a neat subspace interpretation. Furthermore, the approach can be easily generalized to data streams. We present experimental results showing the effectiveness of the approach over other state-of-the-art methods.},
	booktitle = {2016 {IEEE} 16th {International} {Conference} on {Data} {Mining} ({ICDM})},
	author = {Sathe, S. and Aggarwal, C. C.},
	month = dec,
	year = {2016},
	note = {00000},
	keywords = {Detection algorithms, Training, Complexity theory, computational complexity, data analysis, Data models, Detectors, Electronic mail, file organisation, linear complexity, randomized hashing, Robustness, subspace outlier detection algorithm},
	pages = {459--468},
	file = {2016-Sathe-Subspace_Outlier_Detection_in_Linear_Time_with_Randomized_Hashing.pdf:/home/migue/Zotero/storage/D46A9C5I/2016-Sathe-Subspace_Outlier_Detection_in_Linear_Time_with_Randomized_Hashing.pdf:application/pdf;IEEE Xplore Abstract Record:/home/migue/Zotero/storage/QD2C4KPP/7837870.html:text/html}
}

@inproceedings{javitzSRIIDESStatistical1991,
	title = {The {SRI} {IDES} statistical anomaly detector},
	doi = {10.1109/RISP.1991.130799},
	abstract = {SRI International's real-time intrusion-detection expert system (IDES) contains a statistical subsystem that observes behavior on a monitored computer system and adaptively learns what is normal for individual users and groups of users. The statistical subsystem also monitors observed behavior and identifies behavior as a potential intrusion (or misuse by authorized users) if it deviates significantly from expected behavior. The multivariate methods used to profile normal behavior and identify deviations from expected behavior are explained in detail. The statistical test for abnormality contains a number of parameters that must be initialized and the substantive issues relating to setting those parameter values are discussed.{\textless}{\textless}ETX{\textgreater}{\textgreater}},
	booktitle = {Proceedings. 1991 {IEEE} {Computer} {Society} {Symposium} on {Research} in {Security} and {Privacy}},
	author = {Javitz, H. S. and Valdes, A.},
	month = may,
	year = {1991},
	note = {00000},
	keywords = {Intrusion detection, security of data, Detectors, adaptive systems, adaptively learns, Aging, authorized users, Computerized monitoring, Condition monitoring, expert systems, Expert systems, Frequency, IDES, learning systems, monitored computer system, Real time systems, real-time intrusion-detection expert system, real-time systems, SRI, statistical anomaly detector, Statistics, System testing},
	pages = {316--326},
	file = {1991-Javitz-The_SRI_IDES_statistical_anomaly_detector.pdf:/home/migue/Zotero/storage/NY83WUJR/1991-Javitz-The_SRI_IDES_statistical_anomaly_detector.pdf:application/pdf;IEEE Xplore Abstract Record:/home/migue/Zotero/storage/EYECBN5Y/130799.html:text/html}
}

@article{helmanStatisticallyBasedSystem1997,
	title = {A statistically based system for prioritizing information exploration under uncertainty},
	volume = {27},
	issn = {1083-4427},
	doi = {10.1109/3468.594912},
	abstract = {This paper examines the problem of prioritizing actions under uncertainty. Our motivating applications come from the domain of data mining. Data mining problems present the user with a huge collection of individual items (e.g., abstracts, medical histories, and computer users' command histories) and require that these items be prioritized according to which should be pursued thoroughly. More precisely, each data item is assumed to be generated by one of two processes: A large majority of the data comes from a common, mundane process and a very small fraction comes from a rare, phenomenon process. The problem is to rank the information so as to optimally direct the user in his or her pursuit of the data items that were generated by the phenomenon process. Our previous work has developed the theoretical foundations of the information prioritization problem. The current paper summarizes these foundations, derives new theoretical results, and details initial experimental results of a prioritization system based on the theory. We focus here on feature selection techniques and the method of model surrogates, each tailored to the classes of prioritization applications of greatest current interest. Our results demonstrate the effectiveness of the techniques and motivate further research to improve the existing system.},
	number = {4},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans},
	author = {Helman, P. and Bhangoo, J.},
	month = jul,
	year = {1997},
	note = {00000},
	keywords = {data mining, statistical analysis, Uncertainty, Data analysis, Detectors, Frequency, Abstracts, Application software, Biomedical imaging, Computer science, Data mining, History, information exploration prioritization, knowledge acquisition, statistically based system, uncertainty},
	pages = {449--466},
	file = {1997-Helman-A_statistically_based_system_for_prioritizing_information_exploration_under.pdf:/home/migue/Zotero/storage/RJ9VLXX7/1997-Helman-A_statistically_based_system_for_prioritizing_information_exploration_under.pdf:application/pdf;IEEE Xplore Abstract Record:/home/migue/Zotero/storage/5IVIN6CL/594912.html:text/html}
}

@inproceedings{pokrajacIncrementalLocalOutlier2007,
	title = {Incremental {Local} {Outlier} {Detection} for {Data} {Streams}},
	doi = {10.1109/CIDM.2007.368917},
	abstract = {Outlier detection has recently become an important problem in many industrial and financial applications. This problem is further complicated by the fact that in many cases, outliers have to be detected from data streams that arrive at an enormous pace. In this paper, an incremental LOF (local outlier factor) algorithm, appropriate for detecting outliers in data streams, is proposed. The proposed incremental LOF algorithm provides equivalent detection performance as the iterated static LOF algorithm (applied after insertion of each data record), while requiring significantly less computational time. In addition, the incremental LOF algorithm also dynamically updates the profiles of data points. This is a very important property, since data profiles may change over time. The paper provides theoretical evidence that insertion of a new data point as well as deletion of an old data point influence only limited number of their closest neighbors and thus the number of updates per such insertion/deletion does not depend on the total number of points TV in the data set. Our experiments performed on several simulated and real life data sets have demonstrated that the proposed incremental LOF algorithm is computationally efficient, while at the same time very successful in detecting outliers and changes of distributional behavior in various data stream applications},
	booktitle = {2007 {IEEE} {Symposium} on {Computational} {Intelligence} and {Data} {Mining}},
	author = {Pokrajac, D. and Lazarevic, A. and Latecki, L. J.},
	month = mar,
	year = {2007},
	note = {00000},
	keywords = {data handling, Intrusion detection, Unsupervised learning, Data mining, Change detection algorithms, Computational Intelligence Society, Computer networks, data streams, Event detection, incremental local outlier detection, local outlier factor algorithm, Telecommunication traffic, Traffic control, Video surveillance},
	pages = {504--515},
	file = {2007-Pokrajac-Incremental_Local_Outlier_Detection_for_Data_Streams.pdf:/home/migue/Zotero/storage/NI6SBTU7/2007-Pokrajac-Incremental_Local_Outlier_Detection_for_Data_Streams.pdf:application/pdf;IEEE Xplore Abstract Record:/home/migue/Zotero/storage/RXZ2GP38/4221341.html:text/html}
}

@inproceedings{chawlaLocalSpatialOutliers2004,
	title = {On local spatial outliers},
	doi = {10.1109/ICDM.2004.10097},
	abstract = {We propose a measure, spatial local outlier measure (SLOM) which captures the local behaviour of datum in their spatial neighborhood. With the help of SLOM, we are able to discern local spatial outliers which are usually missed by global techniques like "three standard deviations away from the mean". Furthermore, the measure takes into account the local stability around a data point and supresses the reporting of outliers in highly unstable areas, where data is too heterogeneous and the notion of outliers is not meaningful. We prove several properties of SLOM and report experiments on synthetic and real data sets which show that our approach is scalable to large data sets.},
	booktitle = {Fourth {IEEE} {International} {Conference} on {Data} {Mining} ({ICDM}'04)},
	author = {Chawla, {and} S.},
	month = nov,
	year = {2004},
	note = {00000},
	keywords = {data mining, very large databases, Information technology, Data mining, Area measurement, Australia, Chebyshev approximation, large data sets, local spatial outliers, Ocean temperature, Sea measurements, Sea surface, SLOM, spatial local outlier measure, spatial neighborhood, Stability, Sun, visual databases},
	pages = {209--216},
	file = {2004-Chawla-On_local_spatial_outliers.pdf:/home/migue/Zotero/storage/WXWPHP7V/2004-Chawla-On_local_spatial_outliers.pdf:application/pdf;IEEE Xplore Abstract Record:/home/migue/Zotero/storage/EZWGF7LS/1410286.html:text/html}
}

@article{heDiscoveringClusterbasedLocal2003,
	title = {Discovering cluster-based local outliers},
	volume = {24},
	number = {9-10},
	journal = {Pattern Recognition Letters},
	author = {He, Zengyou and Xu, Xiaofei and Deng, Shengchun},
	year = {2003},
	keywords = {Outlier detection, Data mining, Clustering},
	pages = {1641--1650},
	file = {2003-He-Discovering_cluster-based_local_outliers.pdf:/home/migue/Zotero/storage/LW5LEAVC/2003-He-Discovering_cluster-based_local_outliers.pdf:application/pdf;2003-He-Discovering_cluster-based_local_outliers.pdf:/home/migue/Zotero/storage/B2WU5D25/2003-He-Discovering_cluster-based_local_outliers.pdf:application/pdf;ScienceDirect Snapshot:/home/migue/Zotero/storage/AFSITX3A/S0167865503000035.html:text/html;ScienceDirect Snapshot:/home/migue/Zotero/storage/J3N3A2CD/S0167865503000035.html:text/html}
}

@inproceedings{tangEnhancingEffectivenessOutlier2002,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Enhancing {Effectiveness} of {Outlier} {Detections} for {Low} {Density} {Patterns}},
	isbn = {978-3-540-47887-4},
	abstract = {Outlier detection is concerned with discovering exceptional behaviors of objects in data sets. It is becoming a growingly useful tool in applications such as credit card fraud detection, discovering criminal behaviors in e-commerce, identifying computer intrusion, detecting health problems, etc. In this paper, we introduce a connectivity-based outlier factor (COF) scheme that improves the effectiveness of an existing local outlier factor (LOF) scheme when a pattern itself has similar neighbourhood density as an outlier. We give theoretical and empirical analysis to demonstrate the improvement in effectiveness and the capability of the COF scheme in comparison with the LOF scheme.},
	language = {en},
	booktitle = {Advances in {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {Springer Berlin Heidelberg},
	author = {Tang, Jian and Chen, Zhixiang and Fu, Ada Wai-chee and Cheung, David W.},
	editor = {Chen, Ming-Syan and Yu, Philip S. and Liu, Bing},
	year = {2002},
	note = {00000},
	keywords = {Outlier Detection, Exceptional Behavior, Large Data Base, Local Outlier Factor, Reachability Distance},
	pages = {535--548},
	file = {2002-Tang-Enhancing_Effectiveness_of_Outlier_Detections_for_Low_Density_Patterns.pdf:/home/migue/Zotero/storage/DE9FEV4T/2002-Tang-Enhancing_Effectiveness_of_Outlier_Detections_for_Low_Density_Patterns.pdf:application/pdf}
}

@inproceedings{jinRankingOutliersUsing2006,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Ranking {Outliers} {Using} {Symmetric} {Neighborhood} {Relationship}},
	isbn = {978-3-540-33207-7},
	abstract = {Mining outliers in database is to find exceptional objects that deviate from the rest of the data set. Besides classical outlier analysis algorithms, recent studies have focused on mining local outliers, i.e., the outliers that have density distribution significantly different from their neighborhood. The estimation of density distribution at the location of an object has so far been based on the density distribution of its k-nearest neighbors [2,11]. However, when outliers are in the location where the density distributions in the neighborhood are significantly different, for example, in the case of objects from a sparse cluster close to a denser cluster, this may result in wrong estimation. To avoid this problem, here we propose a simple but effective measure on local outliers based on a symmetric neighborhood relationship. The proposed measure considers both neighbors and reverse neighbors of an object when estimating its density distribution. As a result, outliers so discovered are more meaningful. To compute such local outliers efficiently, several mining algorithms are developed that detects top-n outliers based on our definition. A comprehensive performance evaluation and analysis shows that our methods are not only efficient in the computation but also more effective in ranking outliers.},
	language = {en},
	booktitle = {Advances in {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {Springer Berlin Heidelberg},
	author = {Jin, Wen and Tung, Anthony K. H. and Han, Jiawei and Wang, Wei},
	editor = {Ng, Wee-Keong and Kitsuregawa, Masaru and Li, Jianzhong and Chang, Kuiyu},
	year = {2006},
	note = {00000},
	keywords = {Neighbor Query, Outlier Detection, Local Outlier, Mining Algorithm, Neighboring Object},
	pages = {577--593},
	file = {2006-Jin-Ranking_Outliers_Using_Symmetric_Neighborhood_Relationship.pdf:/home/migue/Zotero/storage/XSCYCFCP/2006-Jin-Ranking_Outliers_Using_Symmetric_Neighborhood_Relationship.pdf:application/pdf}
}

@inproceedings{chiuEnhancementsLocalOutlier2003,
	title = {Enhancements on local outlier detection},
	doi = {10.1109/IDEAS.2003.1214939},
	abstract = {Outliers, commonly referred to as exceptional cases, exist in many real-world databases. Detection of such outliers is important for many applications. In this paper, we focus on the density-based notion that discovers local outliers by means of the local outlier factor (LOF) formulation. Three enhancement schemes over LOF are introduced, namely LOF' and LOF" and GridLOF. Thorough explanation and analysis is given to demonstrate the abilities of LOF' in providing simpler and more intuitive meaning of local outlier-ness; LOF" in handling cases where LOF fails to work appropriately; and GridLOF in improving the efficiency and accuracy.},
	booktitle = {Seventh {International} {Database} {Engineering} and {Applications} {Symposium}, 2003. {Proceedings}.},
	author = {Chiu, A. L. M. and {Fu, Ada Wai-Chee}},
	month = jul,
	year = {2003},
	note = {00000},
	keywords = {Data engineering, data mining, Clustering algorithms, expert systems, Application software, Computer science, Credit cards, database management systems, Databases, density-based notion, exceptional case, Failure analysis, GridLOF, inference mechanisms, intuitive local outlierness, KDD, knowledge discovery in databases, local outlier detection enhancement, local outlier discovery, local outlier factor, LOF accuracy improvement, LOF efficiency improvement, LOF failure, LOF formulation, LOF', LOF", Optical noise, Statistical distributions, Telecommunications},
	pages = {298--307},
	file = {2003-and-Enhancements_on_local_outlier_detection.pdf:/home/migue/Zotero/storage/84BW3WZZ/2003-and-Enhancements_on_local_outlier_detection.pdf:application/pdf;IEEE Xplore Abstract Record:/home/migue/Zotero/storage/B8F2FCSB/1214939.html:text/html}
}

@inproceedings{jinMiningTopnLocal2001,
	address = {New York, NY, USA},
	series = {{KDD} '01},
	title = {Mining {Top}-n {Local} {Outliers} in {Large} {Databases}},
	isbn = {978-1-58113-391-2},
	url = {http://doi.acm.org/10.1145/502512.502554},
	doi = {10.1145/502512.502554},
	abstract = {Outlier detection is an important task in data mining with numerous applications, including credit card fraud detection, video surveillance, etc. A recent work on outlier detection has introduced a novel notion of local outlier in which the degree to which an object is outlying is dependent on the density of its local neighborhood, and each object can be assigned a Local Outlier Factor (LOF) which represents the likelihood of that object being an outlier. Although the concept of local outliers is a useful one, the computation of LOF values for every data objects requires a large number of \&kgr;-nearest neighbors searches and can be computationally expensive. Since most objects are usually not outliers, it is useful to provide users with the option of finding only n most outstanding local outliers, i.e., the top-n data objects which are most likely to be local outliers according to their LOFs. However, if the pruning is not done carefully, finding top-n outliers could result in the same amount of computation as finding LOF for all objects. In this paper, we propose a novel method to efficiently find the top-n local outliers in large databases. The concept of "micro-cluster" is introduced to compress the data. An efficient micro-cluster-based local outlier mining algorithm is designed based on this concept. As our algorithm can be adversely affected by the overlapping in the micro-clusters, we proposed a meaningful cut-plane solution for overlapping data. The formal analysis and experiments show that this method can achieve good performance in finding the most outstanding local outliers.},
	urldate = {2019-03-15},
	booktitle = {Proceedings of the {Seventh} {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {ACM},
	author = {Jin, Wen and Tung, Anthony K. H. and Han, Jiawei},
	year = {2001},
	note = {00000 
event-place: San Francisco, California},
	pages = {293--298},
	file = {2001-Jin-Mining_Top-n_Local_Outliers_in_Large_Databases.pdf:/home/migue/Zotero/storage/6BTUWXWT/2001-Jin-Mining_Top-n_Local_Outliers_in_Large_Databases.pdf:application/pdf}
}

@inproceedings{hautamakiOutlierDetectionUsing2004,
	title = {Outlier detection using k-nearest neighbour graph},
	volume = {3},
	doi = {10.1109/ICPR.2004.1334558},
	abstract = {We present an outlier detection using indegree number (ODIN) algorithm that utilizes k-nearest neighbour graph. Improvements to existing kNN distance-based method are also proposed. We compare the methods with real and synthetic datasets. The results show that the proposed method achieves reasonable results with synthetic data and outperforms compared methods with real data sets with small number of observations.},
	booktitle = {Proceedings of the 17th {International} {Conference} on {Pattern} {Recognition}, 2004. {ICPR} 2004.},
	author = {Hautamaki, V. and Karkkainen, I. and Franti, P.},
	month = aug,
	year = {2004},
	note = {00000},
	keywords = {Intrusion detection, Computer science, Data mining, Statistical distributions, Breast cancer, Cancer detection, Computer security, distance based method, Gaussian distribution, graph theory, indegree number algorithm, k-nearest neighbour graph, outlier detection algorithm, pattern clustering, Pattern recognition, Probability density function},
	pages = {430--433 Vol.3},
	file = {2004-Hautamaki-Outlier_detection_using_k-nearest_neighbour_graph.pdf:/home/migue/Zotero/storage/SB8HNG3Y/2004-Hautamaki-Outlier_detection_using_k-nearest_neighbour_graph.pdf:application/pdf;IEEE Xplore Abstract Record:/home/migue/Zotero/storage/SMX8PQ4N/1334558.html:text/html}
}

@article{britoConnectivityMutualKnearestneighbor1997,
	title = {Connectivity of the mutual k-nearest-neighbor graph in clustering and outlier detection},
	volume = {35},
	issn = {0167-7152},
	url = {http://www.sciencedirect.com/science/article/pii/S0167715296002131},
	doi = {10.1016/S0167-7152(96)00213-1},
	abstract = {For multivariate data sets, we study the relationship between the connectivity of a mutual k-nearest-neighbor graph, and the presence of clustering structure and outliers in the data. A test for detection of clustering structure and outliers is proposed and its performance is evaluated in simulated data.},
	number = {1},
	urldate = {2019-03-15},
	journal = {Statistics \& Probability Letters},
	author = {Brito, M. R. and Chávez, E. L. and Quiroz, A. J. and Yukich, J. E.},
	month = aug,
	year = {1997},
	note = {00000},
	keywords = {Outlier detection, Clustering, Mutual nearest neighbors},
	pages = {33--42},
	file = {1997-Brito-Connectivity_of_the_mutual_k-nearest-neighbor_graph_in_clustering_and_outlier.pdf:/home/migue/Zotero/storage/G4X4KKDF/1997-Brito-Connectivity_of_the_mutual_k-nearest-neighbor_graph_in_clustering_and_outlier.pdf:application/pdf;ScienceDirect Snapshot:/home/migue/Zotero/storage/CJTJX8GN/S0167715296002131.html:text/html}
}

@inproceedings{breunigOPTICSOFIdentifyingLocal1999,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{OPTICS}-{OF}: {Identifying} {Local} {Outliers}},
	isbn = {978-3-540-48247-5},
	shorttitle = {{OPTICS}-{OF}},
	abstract = {For many KDD applications finding the outliers, i.e. the rare events, is more interesting and useful than finding the common cases, e.g. detecting criminal activities in E-commerce. Being an outlier, however, is not just a binary property. Instead, it is a property that applies to a certain degree to each object in a data set, depending on how ‘isolated’ this object is, with respect to the surrounding clustering structure. In this paper, we formally introduce a new notion of outliers which bases outlier detection on the same theoretical foundation as density-based cluster analysis. Our notion of an outlier is ‘local’ in the sense that the outlier-degree of an object is determined by taking into account the clustering structure in a bounded neighborhood of the object. We demonstrate that this notion of an outlier is more appropriate for detecting different types of outliers than previous approaches, and we also present an algorithm for finding them. Furthermore, we show that by combining the outlier detection with a density-based method to analyze the clustering structure, we can get the outliers almost for free if we already want to perform a cluster analysis on a data set.},
	language = {en},
	booktitle = {Principles of {Data} {Mining} and {Knowledge} {Discovery}},
	publisher = {Springer Berlin Heidelberg},
	author = {Breunig, Markus M. and Kriegel, Hans-Peter and Ng, Raymond T. and Sander, Jörg},
	editor = {Żytkow, Jan M. and Rauch, Jan},
	year = {1999},
	note = {00000},
	keywords = {Outlier Detection, Local Outlier, Cluster Structure, Core Object, Fraud Detection},
	pages = {262--270},
	file = {1999-Breunig-OPTICS-OF.pdf:/home/migue/Zotero/storage/AVIU64PX/1999-Breunig-OPTICS-OF.pdf:application/pdf}
}

@inproceedings{kontakiContinuousMonitoringDistancebased2011,
	title = {Continuous monitoring of distance-based outliers over data streams},
	doi = {10.1109/ICDE.2011.5767923},
	abstract = {Anomaly detection is considered an important data mining task, aiming at the discovery of elements (also known as outliers) that show significant diversion from the expected case. More specifically, given a set of objects the problem is to return the suspicious objects that deviate significantly from the typical behavior. As in the case of clustering, the application of different criteria lead to different definitions for an outlier. In this work, we focus on distance-based outliers: an object x is an outlier if there are less than k objects lying at distance at most R from x. The problem offers significant challenges when a stream-based environment is considered, where data arrive continuously and outliers must be detected on-the-fly. There are a few research works studying the problem of continuous outlier detection. However, none of these proposals meets the requirements of modern stream-based applications for the following reasons: (i) they demand a significant storage overhead, (ii) their efficiency is limited and (iii) they lack flexibility. In this work, we propose new algorithms for continuous outlier monitoring in data streams, based on sliding windows. Our techniques are able to reduce the required storage overhead, run faster than previously proposed techniques and offer significant flexibility. Experiments performed on real-life as well as synthetic data sets verify our theoretical study.},
	booktitle = {2011 {IEEE} 27th {International} {Conference} on {Data} {Engineering}},
	author = {Kontaki, M. and Gounaris, A. and Papadopoulos, A. N. and Tsichlas, K. and Manolopoulos, Y.},
	month = apr,
	year = {2011},
	note = {00000},
	keywords = {data mining, Detection algorithms, Algorithm design and analysis, Monitoring, security of data, Data mining, data streams, pattern clustering, anomaly detection, continuous distance-based outlier monitoring, data mining task, Data structures, Heuristic algorithms, Measurement, sliding windows, synthetic data sets},
	pages = {135--146},
	file = {2011-Kontaki-Continuous_monitoring_of_distance-based_outliers_over_data_streams.pdf:/home/migue/Zotero/storage/WA26WIQT/2011-Kontaki-Continuous_monitoring_of_distance-based_outliers_over_data_streams.pdf:application/pdf;IEEE Xplore Abstract Record:/home/migue/Zotero/storage/KNMGKZSM/5767923.html:text/html}
}

@inproceedings{angiulliDetectingDistancebasedOutliers2007,
	address = {New York, NY, USA},
	series = {{CIKM} '07},
	title = {Detecting {Distance}-based {Outliers} in {Streams} of {Data}},
	isbn = {978-1-59593-803-9},
	url = {http://doi.acm.org/10.1145/1321440.1321552},
	doi = {10.1145/1321440.1321552},
	abstract = {In this work a method for detecting distance-based outliers in data streams is presented. We deal with the sliding window model, where outlier queries are performed in order to detect anomalies in the current window. Two algorithms are presented. The first one exactly answers outlier queries, but has larger space requirements. The second algorithm is directly derived from the exact one, has limited memory requirements and returns an approximate answer based on accurate estimations with a statistical guarantee. Several experiments have been accomplished, confirming the effectiveness of the proposed approach and the high quality of approximate solutions.},
	urldate = {2019-03-15},
	booktitle = {Proceedings of the {Sixteenth} {ACM} {Conference} on {Conference} on {Information} and {Knowledge} {Management}},
	publisher = {ACM},
	author = {Angiulli, Fabrizio and Fassetti, Fabio},
	year = {2007},
	note = {00000 
event-place: Lisbon, Portugal},
	keywords = {data streams, anomaly detection, distance-based outliers},
	pages = {811--820},
	file = {2007-Angiulli-Detecting_Distance-based_Outliers_in_Streams_of_Data.pdf:/home/migue/Zotero/storage/J7WYNJVH/2007-Angiulli-Detecting_Distance-based_Outliers_in_Streams_of_Data.pdf:application/pdf}
}

@inproceedings{bhaduriAlgorithmsSpeedingDistancebased2011,
	address = {New York, NY, USA},
	series = {{KDD} '11},
	title = {Algorithms for {Speeding} {Up} {Distance}-based {Outlier} {Detection}},
	isbn = {978-1-4503-0813-7},
	url = {http://doi.acm.org/10.1145/2020408.2020554},
	doi = {10.1145/2020408.2020554},
	abstract = {The problem of distance-based outlier detection is difficult to solve efficiently in very large datasets because of potential quadratic time complexity. We address this problem and develop sequential and distributed algorithms that are significantly more efficient than state-of-the-art methods while still guaranteeing the same outliers. By combining simple but effective indexing and disk block accessing techniques, we have developed a sequential algorithm iOrca that is up to an order-of-magnitude faster than the state-of-the-art. The indexing scheme is based on sorting the data points in order of increasing distance from a fixed reference point and then accessing those points based on this sorted order. To speed up the basic outlier detection technique, we develop two distributed algorithms (DOoR and iDOoR) for modern distributed multi-core clusters of machines, connected on a ring topology. The first algorithm passes data blocks from each machine around the ring, incrementally updating the nearest neighbors of the points passed. By maintaining a cutoff threshold, it is able to prune a large number of points in a distributed fashion. The second distributed algorithm extends this basic idea with the indexing scheme discussed earlier. In our experiments, both distributed algorithms exhibit significant improvements compared to the state-of-the-art distributed method [13].},
	urldate = {2019-03-15},
	booktitle = {Proceedings of the 17th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {ACM},
	author = {Bhaduri, Kanishka and Matthews, Bryan L. and Giannella, Chris R.},
	year = {2011},
	note = {00000 
event-place: San Diego, California, USA},
	keywords = {outlier detection, distributed computing, nearest neighbor},
	pages = {859--867},
	file = {2011-Bhaduri-Algorithms_for_Speeding_Up_Distance-based_Outlier_Detection.pdf:/home/migue/Zotero/storage/UKXAJ7TE/2011-Bhaduri-Algorithms_for_Speeding_Up_Distance-based_Outlier_Detection.pdf:application/pdf}
}

@inproceedings{peiEfficientReferenceBasedApproach2006,
	title = {An {Efficient} {Reference}-{Based} {Approach} to {Outlier} {Detection} in {Large} {Datasets}},
	doi = {10.1109/ICDM.2006.17},
	abstract = {A bottleneck to detecting distance and density based outliers is that a nearest-neighbor search is required for each of the data points, resulting in a quadratic number of pairwise distance evaluations. In this paper, we propose a new method that uses the relative degree of density with respect to a fixed set of reference points to approximate the degree of density defined in terms of nearest neighbors of a data point. The running time of our algorithm based on this approximation is 0(Rn log n) where n is the size of dataset and R is the number of reference points. Candidate outliers are ranked based on the outlier score assigned to each data point. Theoretical analysis and empirical studies show that our method is effective, efficient, and highly scalable to very large datasets.},
	booktitle = {Sixth {International} {Conference} on {Data} {Mining} ({ICDM}'06)},
	author = {Pei, Y. and Zaiane, O. R. and Gao, Y.},
	month = dec,
	year = {2006},
	note = {00000},
	keywords = {approximation theory, outlier detection, Clustering algorithms, Approximation algorithms, computational complexity, Computer science, Data mining, Statistical distributions, Art, density based outliers, density degree approximation, distance detection, Distributed computing, large datasets, Nearest neighbor searches, nearest-neighbor search, pairwise distance evaluations, pattern recognition, reference-based approach, search problems, Spatial indexes, Tree data structures},
	pages = {478--487},
	file = {2006-Pei-An_Efficient_Reference-Based_Approach_to_Outlier_Detection_in_Large_Datasets.pdf:/home/migue/Zotero/storage/HQKS7SQ2/2006-Pei-An_Efficient_Reference-Based_Approach_to_Outlier_Detection_in_Large_Datasets.pdf:application/pdf;IEEE Xplore Abstract Record:/home/migue/Zotero/storage/MV7DICB4/4053074.html:text/html}
}

@inproceedings{taoMiningDistancebasedOutliers2006,
	address = {New York, NY, USA},
	series = {{KDD} '06},
	title = {Mining {Distance}-based {Outliers} from {Large} {Databases} in {Any} {Metric} {Space}},
	isbn = {978-1-59593-339-3},
	url = {http://doi.acm.org/10.1145/1150402.1150447},
	doi = {10.1145/1150402.1150447},
	abstract = {Let R be a set of objects. An object o ∈ R is an outlier, if there exist less than k objects in R whose distances to o are at most r. The values of k, r, and the distance metric are provided by a user at the run time. The objective is to return all outliers with the smallest I/O cost.This paper considers a generic version of the problem, where no information is available for outlier computation, except for objects' mutual distances. We prove an upper bound for the memory consumption which permits the discovery of all outliers by scanning the dataset 3 times. The upper bound turns out to be extremely low in practice, e.g., less than 1\% of R. Since the actual memory capacity of a realistic DBMS is typically larger, we develop a novel algorithm, which integrates our theoretical findings with carefully-designed heuristics that leverage the additional memory to improve I/O efficiency. Our technique reports all outliers by scanning the dataset at most twice (in some cases, even once), and significantly outperforms the existing solutions by a factor up to an order of magnitude.},
	urldate = {2019-03-15},
	booktitle = {Proceedings of the 12th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {ACM},
	author = {Tao, Yufei and Xiao, Xiaokui and Zhou, Shuigeng},
	year = {2006},
	note = {00000 
event-place: Philadelphia, PA, USA},
	keywords = {outlier, metric data, mining},
	pages = {394--403},
	file = {2006-Tao-Mining_Distance-based_Outliers_from_Large_Databases_in_Any_Metric_Space.pdf:/home/migue/Zotero/storage/D8TCRN8Q/2006-Tao-Mining_Distance-based_Outliers_from_Large_Databases_in_Any_Metric_Space.pdf:application/pdf}
}

@inproceedings{fanNonparametricOutlierDetection2006,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {A {Nonparametric} {Outlier} {Detection} for {Effectively} {Discovering} {Top}-{N} {Outliers} from {Engineering} {Data}},
	isbn = {978-3-540-33207-7},
	abstract = {We present a novel resolution-based outlier notion and a nonparametric outlier-mining algorithm, which can efficiently identify top listed outliers from a wide variety of datasets. The algorithm generates reasonable outlier results by taking both local and global features of a dataset into consideration. Experiments are conducted using both synthetic datasets and a real life construction equipment dataset from a large building contractor. Comparison with the current outlier mining algorithms indicates that the proposed algorithm is more effective.},
	language = {en},
	booktitle = {Advances in {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {Springer Berlin Heidelberg},
	author = {Fan, Hongqin and Zaïane, Osmar R. and Foss, Andrew and Wu, Junfeng},
	editor = {Ng, Wee-Keong and Kitsuregawa, Masaru and Li, Jianzhong and Chang, Kuiyu},
	year = {2006},
	note = {00000},
	keywords = {Outlier Detection, Local Outlier, Mining Algorithm, Close Neighbour, Synthetic Dataset},
	pages = {557--566},
	file = {2006-Fan-A_Nonparametric_Outlier_Detection_for_Effectively_Discovering_Top-N_Outliers.pdf:/home/migue/Zotero/storage/JXLXMXAG/2006-Fan-A_Nonparametric_Outlier_Detection_for_Effectively_Discovering_Top-N_Outliers.pdf:application/pdf}
}

@article{jarvisClusteringUsingSimilarity1973,
	title = {Clustering {Using} a {Similarity} {Measure} {Based} on {Shared} {Near} {Neighbors}},
	volume = {C-22},
	issn = {0018-9340},
	doi = {10.1109/T-C.1973.223640},
	abstract = {A nonparametric clustering technique incorporating the concept of similarity based on the sharing of near neighbors is presented. In addition to being an essentially paraliel approach, the computational elegance of the method is such that the scheme is applicable to a wide class of practical problems involving large sample size and high dimensionality. No attempt is made to show how a priori problem knowledge can be introduced into the procedure.},
	number = {11},
	journal = {IEEE Transactions on Computers},
	author = {Jarvis, R. A. and Patrick, E. A.},
	month = nov,
	year = {1973},
	note = {00000},
	keywords = {Clustering, nonparametric, pattern recognition, shared near neighbors, similarity measure.},
	pages = {1025--1034},
	file = {1973-Jarvis-Clustering_Using_a_Similarity_Measure_Based_on_Shared_Near_Neighbors.pdf:/home/migue/Zotero/storage/686YFKBS/1973-Jarvis-Clustering_Using_a_Similarity_Measure_Based_on_Shared_Near_Neighbors.pdf:application/pdf;IEEE Xplore Abstract Record:/home/migue/Zotero/storage/HLBCK4DM/1672233.html:text/html}
}

@inproceedings{tingOvercomingKeyWeaknesses2016,
	address = {San Francisco, California, USA},
	title = {Overcoming {Key} {Weaknesses} of {Distance}-based {Neighbourhood} {Methods} using a {Data} {Dependent} {Dissimilarity} {Measure}},
	isbn = {978-1-4503-4232-2},
	url = {http://dl.acm.org/citation.cfm?doid=2939672.2939779},
	doi = {10.1145/2939672.2939779},
	abstract = {This paper introduces the ﬁrst generic version of data dependent dissimilarity and shows that it provides a better closest match than distance measures for three existing algorithms in clustering, anomaly detection and multi-label classiﬁcation. For each algorithm, we show that by simply replacing the distance measure with the data dependent dissimilarity measure, it overcomes a key weakness of the otherwise unchanged algorithm.},
	language = {en},
	urldate = {2019-03-15},
	booktitle = {Proceedings of the 22nd {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} - {KDD} '16},
	publisher = {ACM Press},
	author = {Ting, Kai Ming and Zhu, Ye and Carman, Mark and Zhu, Yue and Zhou, Zhi-Hua},
	year = {2016},
	pages = {1205--1214},
	file = {2016-Ting et al.-Overcoming Key Weaknesses of Distance-based Neighb.pdf:/home/migue/Zotero/storage/KIQVHMMU/2016-Ting et al.-Overcoming Key Weaknesses of Distance-based Neighb.pdf:application/pdf}
}

@article{shiUnsupervisedLearningRandom2006,
	title = {Unsupervised {Learning} {With} {Random} {Forest} {Predictors}},
	volume = {15},
	issn = {1061-8600},
	url = {https://amstat.tandfonline.com/doi/abs/10.1198/106186006X94072},
	doi = {10.1198/106186006X94072},
	abstract = {A random forest (RF) predictor is an ensemble of individual tree predictors. As part of their construction, RF predictors naturally lead to a dissimilarity measure between the observations. One can also define an RF dissimilarity measure between unlabeled data: the idea is to construct an RF predictor that distinguishes the “observed” data from suitably generated synthetic data. The observed data are the original unlabeled data and the synthetic data are drawn from a reference distribution. Here we describe the properties of the RF dissimilarity and make recommendations on how to use it in practice.An RF dissimilarity can be attractive because it handles mixed variable types well, is invariant to monotonic transformations of the input variables, and is robust to outlying observations. The RF dissimilarity easily deals with a large number of variables due to its intrinsic variable selection; for example, the Addcl 1 RF dissimilarity weighs the contribution of each variable according to how dependent it is on other variables.We find that the RF dissimilarity is useful for detecting tumor sample clusters on the basis of tumor marker expressions. In this application, biologically meaningful clusters can often be described with simple thresholding rules.},
	number = {1},
	urldate = {2019-03-15},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Shi, Tao and Horvath, Steve},
	month = mar,
	year = {2006},
	note = {00000},
	pages = {118--138},
	file = {2006-Shi y Horvath-Unsupervised Learning With Random Forest Predictor.pdf:/home/migue/Zotero/storage/UL83YPJ9/2006-Shi y Horvath-Unsupervised Learning With Random Forest Predictor.pdf:application/pdf;Snapshot:/home/migue/Zotero/storage/PGQZRPJF/106186006X94072.html:text/html}
}

@inproceedings{wuOutlierDetectionSampling2006,
	address = {New York, NY, USA},
	series = {{KDD} '06},
	title = {Outlier {Detection} by {Sampling} with {Accuracy} {Guarantees}},
	isbn = {978-1-59593-339-3},
	url = {http://doi.acm.org/10.1145/1150402.1150501},
	doi = {10.1145/1150402.1150501},
	abstract = {An effective approach to detecting anomalous points in a data set
is distance-based outlier detection. This paper describes a simple
sampling algorithm to effciently detect distance-based outliers in
domains where each and every distance computation is very
expensive. Unlike any existing algorithms, the sampling algorithm
requires a xed number of distance computations and can return good
results with accuracy guarantees. The most computationally
expensive aspect of estimating the accuracy of the result is
sorting all of the distances computed by the sampling algorithm.
The experimental study on two expensive domains as well as ten
additional real-life datasets demonstrates both the effciency and
effectiveness of the sampling algorithm in comparison with the
state-of-the-art algorithm and there liability of the accuracy
guarantees.},
	urldate = {2019-03-15},
	booktitle = {Proceedings of the 12th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {ACM},
	author = {Wu, Mingxi and Jermaine, Christopher},
	year = {2006},
	note = {00000 
event-place: Philadelphia, PA, USA},
	keywords = {outlier detection, active learning, ensemble method},
	pages = {767--772},
	file = {2006-Wu-Outlier_Detection_by_Sampling_with_Accuracy_Guarantees.pdf:/home/migue/Zotero/storage/G5J9F9AQ/2006-Wu-Outlier_Detection_by_Sampling_with_Accuracy_Guarantees.pdf:application/pdf}
}

@inproceedings{bayMiningDistancebasedOutliers2003,
	address = {New York, NY, USA},
	series = {{KDD} '03},
	title = {Mining {Distance}-based {Outliers} in {Near} {Linear} {Time} with {Randomization} and a {Simple} {Pruning} {Rule}},
	isbn = {978-1-58113-737-8},
	url = {http://doi.acm.org/10.1145/956750.956758},
	doi = {10.1145/956750.956758},
	abstract = {Defining outliers by their distance to neighboring examples is a popular approach to finding unusual examples in a data set. Recently, much work has been conducted with the goal of finding fast algorithms for this task. We show that a simple nested loop algorithm that in the worst case is quadratic can give near linear time performance when the data is in random order and a simple pruning rule is used. We test our algorithm on real high-dimensional data sets with millions of examples and show that the near linear scaling holds over several orders of magnitude. Our average case analysis suggests that much of the efficiency is because the time to process non-outliers, which are the majority of examples, does not depend on the size of the data set.},
	urldate = {2019-03-15},
	booktitle = {Proceedings of the {Ninth} {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {ACM},
	author = {Bay, Stephen D. and Schwabacher, Mark},
	year = {2003},
	note = {00000 
event-place: Washington, D.C.},
	keywords = {anomaly detection, diskbased algorithms, distance-based operations, outliers},
	pages = {29--38},
	file = {2003-Bay-Mining_Distance-based_Outliers_in_Near_Linear_Time_with_Randomization_and_a.pdf:/home/migue/Zotero/storage/Z354JSJC/2003-Bay-Mining_Distance-based_Outliers_in_Near_Linear_Time_with_Randomization_and_a.pdf:application/pdf}
}

@inproceedings{angiulliFastOutlierDetection2002,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Fast {Outlier} {Detection} in {High} {Dimensional} {Spaces}},
	isbn = {978-3-540-45681-0},
	abstract = {In this paper we propose a new definition of distance-based outlier that considers for each point the sum of the distances from its k nearest neighbors, called weight. Outliers are those points having the largest values of weight. In order to compute these weights, we find the k nearest neighbors of each point in a fast and efficient way by linearizing the search space through the Hilbert space filling curve. The algorithm consists of two phases, the first provides an approximated solution, within a small factor, after executing at most d + 1 scans of the data set with a low time complexity cost, where d is the number of dimensions of the data set. During each scan the number of points candidate to belong to the solution set is sensibly reduced. The second phase returns the exact solution by doing a single scan which examines further a little fraction of the data set. Experimental results show that the algorithm always finds the exact solution during the first phase after d- 《 d + 1 steps and it scales linearly both in the dimensionality and the size of the data set.},
	language = {en},
	booktitle = {Principles of {Data} {Mining} and {Knowledge} {Discovery}},
	publisher = {Springer Berlin Heidelberg},
	author = {Angiulli, Fabrizio and Pizzuti, Clara},
	editor = {Elomaa, Tapio and Mannila, Heikki and Toivonen, Hannu},
	year = {2002},
	note = {00000},
	keywords = {Outlier Detection, Local Outlier, High Dimensional Space, Hilbert Curve, Point Feature},
	pages = {15--27},
	file = {2002-Angiulli-Fast_Outlier_Detection_in_High_Dimensional_Spaces.pdf:/home/migue/Zotero/storage/JMSX74TD/2002-Angiulli-Fast_Outlier_Detection_in_High_Dimensional_Spaces.pdf:application/pdf}
}

@inproceedings{ramaswamyEfficientAlgorithmsMining2000,
	address = {New York, NY, USA},
	series = {{SIGMOD} '00},
	title = {Efficient {Algorithms} for {Mining} {Outliers} from {Large} {Data} {Sets}},
	isbn = {978-1-58113-217-5},
	url = {http://doi.acm.org/10.1145/342009.335437},
	doi = {10.1145/342009.335437},
	abstract = {In this paper, we propose a novel formulation for distance-based outliers that is based on the distance of a point from its kth nearest neighbor. We rank each point on the basis of its distance to its kth nearest neighbor and declare the top n points in this ranking to be outliers. In addition to developing relatively straightforward solutions to finding such outliers based on the classical nested-loop join and index join algorithms, we develop a highly efficient partition-based algorithm for mining outliers. This algorithm first partitions the input data set into disjoint subsets, and then prunes entire partitions as soon as it is determined that they cannot contain outliers. This results in substantial savings in computation. We present the results of an extensive experimental study on real-life and synthetic data sets. The results from a real-life NBA database highlight and reveal several expected and unexpected aspects of the database. The results from a study on synthetic data sets demonstrate that the partition-based algorithm scales well with respect to both data set size and data set dimensionality.},
	urldate = {2019-03-15},
	booktitle = {Proceedings of the 2000 {ACM} {SIGMOD} {International} {Conference} on {Management} of {Data}},
	publisher = {ACM},
	author = {Ramaswamy, Sridhar and Rastogi, Rajeev and Shim, Kyuseok},
	year = {2000},
	note = {00000 
event-place: Dallas, Texas, USA},
	pages = {427--438},
	file = {2000-Ramaswamy-Efficient_Algorithms_for_Mining_Outliers_from_Large_Data_Sets.pdf:/home/migue/Zotero/storage/T4YAPEB9/2000-Ramaswamy-Efficient_Algorithms_for_Mining_Outliers_from_Large_Data_Sets.pdf:application/pdf}
}

@inproceedings{knorrAlgorithmsMiningDistanceBased1998,
	address = {San Francisco, CA, USA},
	series = {{VLDB} '98},
	title = {Algorithms for {Mining} {Distance}-{Based} {Outliers} in {Large} {Datasets}},
	isbn = {978-1-55860-566-4},
	url = {http://dl.acm.org/citation.cfm?id=645924.671334},
	urldate = {2019-03-15},
	booktitle = {Proceedings of the 24rd {International} {Conference} on {Very} {Large} {Data} {Bases}},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Knorr, Edwin M. and Ng, Raymond T.},
	year = {1998},
	note = {00000},
	pages = {392--403},
	file = {1998-Knorr-Algorithms_for_Mining_Distance-Based_Outliers_in_Large_Datasets.pdf:/home/migue/Zotero/storage/UYHNKXLX/1998-Knorr-Algorithms_for_Mining_Distance-Based_Outliers_in_Large_Datasets.pdf:application/pdf}
}

@inproceedings{knorrFindingIntensionalKnowledge1999,
	address = {San Francisco, CA, USA},
	series = {{VLDB} '99},
	title = {Finding {Intensional} {Knowledge} of {Distance}-{Based} {Outliers}},
	isbn = {978-1-55860-615-9},
	url = {http://dl.acm.org/citation.cfm?id=645925.671529},
	urldate = {2019-03-15},
	booktitle = {Proceedings of the 25th {International} {Conference} on {Very} {Large} {Data} {Bases}},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Knorr, Edwin M. and Ng, Raymond T.},
	year = {1999},
	note = {00000},
	pages = {211--222},
	file = {1999-Knorr-Finding_Intensional_Knowledge_of_Distance-Based_Outliers.pdf:/home/migue/Zotero/storage/KE7A6XFN/1999-Knorr-Finding_Intensional_Knowledge_of_Distance-Based_Outliers.pdf:application/pdf}
}

@inproceedings{sunCDTreesEfficientIndex2004,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{CD}-{Trees}: {An} {Efficient} {Index} {Structure} for {Outlier} {Detection}},
	isbn = {978-3-540-27772-9},
	shorttitle = {{CD}-{Trees}},
	abstract = {Outlier detection is to find objects that do not comply with the general behavior of the data. Partition is a kind of method of dividing data space into a set of non-overlapping rectangular cells. There exists very large data skew in real-life datasets so that partition will produce many empty cells. The cell-based algorithms for outlier detection don’t get enough attention to the existence of many empty cells, which affects the efficiency of algorithms. In this paper, we propose the concept of Skew of Data (SOD) to measure the degree of data skew, and which approximates the percentage of empty cells under a partition of a dataset. An efficient index structure called CD-Tree and the related algorithms are designed. This paper applies the CD-Tree to detect outliers. Compared with cell-based algorithms on real-life datasets, the speed of CD-Tree-based algorithm increases 4 times at least and that the number of dimensions processed also increases obviously.},
	language = {en},
	booktitle = {Advances in {Web}-{Age} {Information} {Management}},
	publisher = {Springer Berlin Heidelberg},
	author = {Sun, Huanliang and Bao, Yubin and Zhao, Faxin and Yu, Ge and Wang, Daling},
	editor = {Li, Qing and Wang, Guoren and Feng, Ling},
	year = {2004},
	pages = {600--609},
	file = {2004-Sun-CD-Trees.pdf:/home/migue/Zotero/storage/63CPIAWM/2004-Sun-CD-Trees.pdf:application/pdf}
}

@article{piresUsingClusteringRobust2005,
	title = {Using clustering and robust estimators to detect outliers in multivariate data},
	copyright = {openAccess},
	url = {http://repositorio.uportu.pt:8080/handle/11328/2345},
	abstract = {Introduction 
 
Outlier identi¯cation is important in many applications of multivariate analysis. Either because 
there is some speci¯c interest in ¯nding anomalous observations or as a pre-processing task before 
the application of some multivariate method, in order to preserve the results from possible harmful 
e®ects of those observations. It is also of great interest in discriminant analysis if, when predicting 
group membership, one wants to have the possibility of labelling an observation as "does not belong 
to any of the available groups". The identi¯cation of outliers in multivariate data is usually based 
on Mahalanobis distance. The use of robust estimates of the mean and the covariance matrix 
is advised in order to avoid the masking e®ect (Rousseeuw and von Zomeren, 1990; Rocke and 
Woodru®, 1996; Becker and Gather, 1999). However, the performance of these rules is still highly 
dependent of multivariate normality of the bulk of the data. The aim of the method here described is 
to remove this dependency. The ¯rst version of this method appeared in Santos-Pereira and Pires 
(2002). In this talk we discuss some re¯nements and also the relation with a recently proposed 
similar method (Hardin and Rocke, 2004).},
	language = {eng},
	urldate = {2019-03-14},
	author = {Pires, Ana and Santos-Pereira, Carla},
	year = {2005},
	file = {2005-Pires-Using_clustering_and_robust_estimators_to_detect_outliers_in_multivariate_data.pdf:/home/migue/Zotero/storage/8XTDQLET/2005-Pires-Using_clustering_and_robust_estimators_to_detect_outliers_in_multivariate_data.pdf:application/pdf;2005-Pires-Using_clustering_and_robust_estimators_to_detect_outliers_in_multivariate_data.pdf:/home/migue/Zotero/storage/MECM3QVB/2005-Pires-Using_clustering_and_robust_estimators_to_detect_outliers_in_multivariate_data.pdf:application/pdf;Snapshot:/home/migue/Zotero/storage/8SC6RN8P/2345.html:text/html;Snapshot:/home/migue/Zotero/storage/43UEF6M7/2345.html:text/html}
}

@article{jiangTwophaseClusteringProcess2001,
	title = {Two-phase clustering process for outliers detection},
	volume = {22},
	number = {6-7},
	journal = {Pattern recognition letters},
	author = {Jiang, Mon-Fong and Tseng, Shian-Shyong and Su, Chih-Ming},
	year = {2001},
	keywords = {-means clustering, MST, Outliers, Two-phase clustering},
	pages = {691--700},
	file = {2001-Jiang-Two-phase_clustering_process_for_outliers_detection.pdf:/home/migue/Zotero/storage/NZ6J5DMA/2001-Jiang-Two-phase_clustering_process_for_outliers_detection.pdf:application/pdf;ScienceDirect Snapshot:/home/migue/Zotero/storage/V2EAN8PU/S0167865500001318.html:text/html}
}

@article{heFpoutlierFrequentPattern2005,
	title = {Fp-outlier: {Frequent} pattern based outlier detection.},
	volume = {2},
	shorttitle = {Fp-outlier},
	number = {1},
	journal = {Comput. Sci. Inf. Syst.},
	author = {He, Zengyou and Xu, Xiaofei and Huang, Joshua Zhexue and Deng, Shengchun},
	year = {2005},
	pages = {103--118},
	file = {He et al. - 2005 - FP-Outlier Frequent Pattern Based Outlier Detecti.pdf:/home/migue/Zotero/storage/8QF3XE2M/He et al. - 2005 - FP-Outlier Frequent Pattern Based Outlier Detecti.pdf:application/pdf}
}

@inproceedings{kaufmanFindingGroupsData1990,
	title = {Finding {Groups} in {Data}: {An} {Introduction} to {Cluster} {Analysis}},
	shorttitle = {Finding {Groups} in {Data}},
	abstract = {Description: The Wiley-Interscience Paperback Series consists of selected books that have been made more accessible to consumers in an effort to increase global appeal and general circulation. With these new unabridged softcover volumes, Wiley hopes to extend the lives of these works by making them available to future generations of statisticians, mathematicians, and scientists. "Cluster analysis is the increasingly important and practical subject of finding groupings in data. The authors set out to write a book for the user who does not necessarily have an extensive background in mathematics. They succeed very well." —Mathematical Reviews "Finding Groups in Data [is] a clear, readable, and interesting presentation of a small number of clustering methods. In addition, the book introduced some interesting innovations of applied value to clustering literature." —Journal of Classification "This is a very good, easy-to-read, and practical book. It has many nice features and is highly recommended for students and practitioners in various fields of study." —Technometrics An introduction to the practical application of cluster analysis, this text presents a selection of methods that together can deal with most applications. These methods are chosen for their robustness, consistency, and general applicability. This book discusses various types of data, including interval-scaled and binary variables as well as similarity data, and explains how these can be transformed prior to clustering.},
	author = {Kaufman, L. and Rousseeuw, Peter},
	year = {1990},
	keywords = {Book, Cluster analysis, Experiment, John D. Wiley, Preprocessor, Reflections of signals on conducting lines, Repository, Smoothing (statistical technique), Technometrics, Whole Earth 'Lectronic Link},
	file = {1990-Kaufman-Finding_Groups_in_Data.pdf:/home/migue/Zotero/storage/7H9FECSZ/1990-Kaufman-Finding_Groups_in_Data.pdf:application/pdf}
}

@incollection{heOutlierDetectionIntegrating2002,
	address = {Berlin, Heidelberg},
	title = {Outlier {Detection} {Integrating} {Semantic} {Knowledge}},
	volume = {2419},
	isbn = {978-3-540-44045-1 978-3-540-45703-9},
	url = {http://link.springer.com/10.1007/3-540-45703-8_12},
	urldate = {2019-03-15},
	booktitle = {Advances in {Web}-{Age} {Information} {Management}},
	publisher = {Springer Berlin Heidelberg},
	author = {He, Zengyou and Deng, Shengchun and Xu, Xiaofei},
	editor = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Meng, Xiaofeng and Su, Jianwen and Wang, Yujun},
	year = {2002},
	doi = {10.1007/3-540-45703-8_12},
	pages = {126--131},
	file = {2002-He-Outlier_Detection_Integrating_Semantic_Knowledge.pdf:/home/migue/Zotero/storage/R4MM94KA/2002-He-Outlier_Detection_Integrating_Semantic_Knowledge.pdf:application/pdf}
}

@incollection{eskinGeometricFrameworkUnsupervised2002,
	address = {Boston, MA},
	series = {Advances in {Information} {Security}},
	title = {A {Geometric} {Framework} for {Unsupervised} {Anomaly} {Detection}},
	isbn = {978-1-4615-0953-0},
	url = {https://doi.org/10.1007/978-1-4615-0953-0_4},
	abstract = {Most current intrusion detection systems employ signature-based methods or data mining-based methods which rely on labeled training data. This training data is typically expensive to produce. We present a new geometric framework for unsupervised anomaly detection, which are algorithms that are designed to process unlabeled data. In our framework, data elements are mapped to a feature space which is typically a vector space ℛd. Anomalies are detected by determining which points lies in sparse regions of the feature space. We present two feature maps for mapping data elements to a feature space. Our first map is a data-dependent normalization feature map which we apply to network connections. Our second feature map is a spectrum kernel which we apply to system call traces. We present three algorithms for detecting which points lie in sparse regions of the feature space. We evaluate our methods by performing experiments over network records from the KDD CUP 1999 data set and system call traces from the 1999 Lincoln Labs DARPA evaluation.},
	language = {en},
	urldate = {2019-03-15},
	booktitle = {Applications of {Data} {Mining} in {Computer} {Security}},
	publisher = {Springer US},
	author = {Eskin, Eleazar and Arnold, Andrew and Prerau, Michael and Portnoy, Leonid and Stolfo, Sal},
	editor = {Barbará, Daniel and Jajodia, Sushil},
	year = {2002},
	doi = {10.1007/978-1-4615-0953-0_4},
	keywords = {Outlier Detection, Intrusion Detection, Kernel Functions},
	pages = {77--101}
}

@inproceedings{satheLODESLocalDensity2016,
	title = {{LODES}: {Local} density meets spectral outlier detection},
	shorttitle = {{LODES}},
	booktitle = {Proceedings of the 2016 {SIAM} {International} {Conference} on {Data} {Mining}},
	publisher = {SIAM},
	author = {Sathe, Saket and Aggarwal, Charu},
	year = {2016},
	pages = {171--179},
	file = {2016-Sathe-LODES.pdf:/home/migue/Zotero/storage/8C28GFWL/2016-Sathe-LODES.pdf:application/pdf;Snapshot:/home/migue/Zotero/storage/97Z7X8YQ/1.9781611974348.html:text/html}
}

@inproceedings{breunigLOFIdentifyingDensitybased2000,
	title = {{LOF}: identifying density-based local outliers},
	volume = {29},
	shorttitle = {{LOF}},
	booktitle = {{ACM} sigmod record},
	publisher = {ACM},
	author = {Breunig, Markus M. and Kriegel, Hans-Peter and Ng, Raymond T. and Sander, Jörg},
	year = {2000},
	pages = {93--104},
	file = {2000-Breunig-LOF.pdf:/home/migue/Zotero/storage/WPWRD9YI/2000-Breunig-LOF.pdf:application/pdf;Snapshot:/home/migue/Zotero/storage/KHI5NL63/citation.html:text/html}
}

@inproceedings{barbaraBootstrappingDataMining2003,
	title = {Bootstrapping a data mining intrusion detection system},
	booktitle = {Proceedings of the 2003 {ACM} symposium on {Applied} computing},
	publisher = {ACM},
	author = {Barbará, Daniel and Li, Yi and Couto, Julia and Lin, Jia-Ling and Jajodia, Sushil},
	year = {2003},
	pages = {421--425},
	file = {2003-Barbará-Bootstrapping_a_data_mining_intrusion_detection_system.pdf:/home/migue/Zotero/storage/QNBRV6A2/2003-Barbará-Bootstrapping_a_data_mining_intrusion_detection_system.pdf:application/pdf;Snapshot:/home/migue/Zotero/storage/3PBJL4BZ/citation.html:text/html}
}

@article{bivensNetworkbasedIntrusionDetection2002,
	title = {Network-based intrusion detection using neural networks},
	volume = {12},
	number = {1},
	journal = {Intelligent Engineering Systems through Artificial Neural Networks},
	author = {Bivens, Alan and Palagiri, Chandrika and Smith, Rasheda and Szymanski, Boleslaw and Embrechts, Mark},
	year = {2002},
	pages = {579--584},
	file = {2002-Bivens-Network-based_intrusion_detection_using_neural_networks.pdf:/home/migue/Zotero/storage/ZCEQCWZM/2002-Bivens-Network-based_intrusion_detection_using_neural_networks.pdf:application/pdf}
}

@inproceedings{ottIntegratedClusteringOutlier2014,
	title = {On integrated clustering and outlier detection},
	booktitle = {Advances in neural information processing systems},
	author = {Ott, Lionel and Pang, Linsey and Ramos, Fabio T. and Chawla, Sanjay},
	year = {2014},
	pages = {1359--1367},
	file = {2014-Ott-On_integrated_clustering_and_outlier_detection.pdf:/home/migue/Zotero/storage/Y3VJ6LBV/2014-Ott-On_integrated_clustering_and_outlier_detection.pdf:application/pdf}
}

@article{kolliosEfficientBiasedSampling2003,
	title = {Efficient biased sampling for approximate clustering and outlier detection in large data sets},
	volume = {15},
	issn = {1041-4347},
	doi = {10.1109/TKDE.2003.1232271},
	abstract = {We investigate the use of biased sampling according to the density of the data set to speed up the operation of general data mining tasks, such as clustering and outlier detection in large multidimensional data sets. In density-biased sampling, the probability that a given point will be included in the sample depends on the local density of the data set. We propose a general technique for density-biased sampling that can factor in user requirements to sample for properties of interest and can be tuned for specific data mining tasks. This allows great flexibility and improved accuracy of the results over simple random sampling. We describe our approach in detail, we analytically evaluate it, and show how it can be optimized for approximate clustering and outlier detection. Finally, we present a thorough experimental evaluation of the proposed method, applying density-biased sampling on real and synthetic data sets, and employing clustering and outlier detection algorithms, thus highlighting the utility of our approach.},
	number = {5},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Kollios, G. and Gunopulos, D. and Koudas, N. and Berchtold, S.},
	month = sep,
	year = {2003},
	keywords = {data mining, outlier detection, very large databases, Clustering algorithms, Detection algorithms, Algorithm design and analysis, Data analysis, Data mining, large data sets, pattern clustering, approximate clustering, biased sampling, Computer Society, density-biased sampling, general data mining tasks, large multidimensional data sets, Multidimensional systems, Probability distribution, sampling methods, Sampling methods, simple random sampling, Urban areas, user requirements},
	pages = {1170--1187},
	file = {2003-Kollios-Efficient_biased_sampling_for_approximate_clustering_and_outlier_detection_in.pdf:/home/migue/Zotero/storage/PA75DCEF/2003-Kollios-Efficient_biased_sampling_for_approximate_clustering_and_outlier_detection_in.pdf:application/pdf}
}

@inproceedings{chaudharyVeryFastOutlier2002,
	title = {Very {Fast} {Outlier} {Detection} in {Large} {Multidimensional} {Data} {Sets}.},
	booktitle = {{DMKD}},
	author = {Chaudhary, Amitabh and Szalay, Alexander S. and Moore, Andrew W.},
	year = {2002},
	file = {Chaudhary et al.-Very Fast Outlier Detection in Large Multidimensio.pdf:/home/migue/Zotero/storage/3ZPLX2BE/Chaudhary et al.-Very Fast Outlier Detection in Large Multidimensio.pdf:application/pdf}
}

@phdthesis{portnoyIntrusionDetectionUnlabeled2000,
	title = {Intrusion detection with unlabeled data using clustering},
	url = {https://doi.org/10.7916/D8MP5904},
	abstract = {Intrusions pose a serious security threat in a network environment, and therefore need to be promptly detected and dealt with. New intrusion types, of which detection systems may not even be aware, are the most difficult to detect. Current signature based methods and learning algorithms which rely on labeled data to train, generally can not detect these new intrusions. We present a framework for automatically detecting intrusions, new or otherwise, even if they are yet unknown to the system. In our system, no manually or otherwise classified data is necessary for training. Our method is able to detect many different types of intrusions, while maintaining a low false positive rate.},
	language = {en},
	urldate = {2019-03-14},
	school = {Columbia University},
	author = {Portnoy, Leonid},
	year = {2000},
	doi = {10.7916/D8MP5904},
	file = {2000-Portnoy-Intrusion_detection_with_unlabeled_data_using_clustering.pdf:/home/migue/Zotero/storage/8APDCWI8/2000-Portnoy-Intrusion_detection_with_unlabeled_data_using_clustering.pdf:application/pdf}
}

@inproceedings{oteyNICbasedIntrusionDetection2003,
	address = {New York, NY, USA},
	series = {{KDD} '03},
	title = {Towards {NIC}-based {Intrusion} {Detection}},
	isbn = {978-1-58113-737-8},
	url = {http://doi.acm.org/10.1145/956750.956847},
	doi = {10.1145/956750.956847},
	abstract = {We present and evaluate a NIC-based network intrusion detection system. Intrusion detection at the NIC makes the system potentially tamper-proof and is naturally extensible to work in a distributed setting. Simple anomaly detection and signature detection based models have been implemented on the NIC firmware, which has its own processor and memory. We empirically evaluate such systems from the perspective of quality and performance (bandwidth of acceptable messages) under varying conditions of host load. The preliminary results we obtain are very encouraging and lead us to believe that such NIC-based security schemes could very well be a crucial part of next generation network security systems.},
	urldate = {2019-03-14},
	booktitle = {Proceedings of the {Ninth} {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {ACM},
	author = {Otey, M. and Parthasarathy, S. and Ghoting, A. and Li, G. and Narravula, S. and Panda, D.},
	year = {2003},
	note = {event-place: Washington, D.C.},
	keywords = {data mining, network interface cards, network intrusion detection, network security, NICs},
	pages = {723--728},
	file = {2003-Otey-Towards_NIC-based_Intrusion_Detection.pdf:/home/migue/Zotero/storage/RIHEVLIK/2003-Otey-Towards_NIC-based_Intrusion_Detection.pdf:application/pdf}
}

@article{jainAlgorithmsClusteringData1988,
	title = {Algorithms for clustering data},
	author = {Jain, Anil K. and Dubes, Richard C.},
	year = {1988}
}

@article{goldsteinHistogrambasedOutlierScore2012,
	title = {Histogram-based outlier score (hbos): {A} fast unsupervised anomaly detection algorithm},
	shorttitle = {Histogram-based outlier score (hbos)},
	journal = {KI-2012: Poster and Demo Track},
	author = {Goldstein, Markus and Dengel, Andreas},
	year = {2012},
	pages = {59--63},
	file = {Goldstein y Dengel-Histogram-based Outlier Score (HBOS) A fast Unsup.pdf:/home/migue/Zotero/storage/LT86U6JU/Goldstein y Dengel-Histogram-based Outlier Score (HBOS) A fast Unsup.pdf:application/pdf}
}

@inproceedings{kellerHiCSHighContrast2012,
	title = {{HiCS}: high contrast subspaces for density-based outlier ranking},
	shorttitle = {{HiCS}},
	booktitle = {Data {Engineering} ({ICDE}), 2012 {IEEE} 28th {International} {Conference} on},
	publisher = {IEEE},
	author = {Keller, Fabian and Muller, Emmanuel and Bohm, Klemens},
	year = {2012},
	note = {00198},
	keywords = {data mining, data analysis, Data mining, Probability density function, Atmospheric measurements, conditional dependence, Correlation, Density measurement, density-based outlier ranking, high contrast subspace projection, Joints, Noise level, outlier mining, outlier ranking algorithm, quality enhancement, subspace dimension, subspace search method},
	pages = {1037--1048}
}

@inproceedings{zhangNewLocalDistancebased2009,
	title = {A new local distance-based outlier detection approach for scattered real-world data},
	booktitle = {Pacific-{Asia} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {Springer},
	author = {Zhang, Ke and Hutter, Marcus and Jin, Huidong},
	year = {2009},
	note = {00261},
	pages = {813--822},
	file = {2009-Zhang-A_new_local_distance-based_outlier_detection_approach_for_scattered_real-world.pdf:/home/migue/Zotero/storage/UW5MK4Y6/2009-Zhang-A_new_local_distance-based_outlier_detection_approach_for_scattered_real-world.pdf:application/pdf;Snapshot:/home/migue/Zotero/storage/W5DFR9XD/978-3-642-01307-2_84.html:text/html}
}

@inproceedings{vriesFindingLocalAnomalies2010,
	title = {Finding {Local} {Anomalies} in {Very} {High} {Dimensional} {Space}},
	doi = {10.1109/ICDM.2010.151},
	abstract = {Time, cost and energy efficiency are critical factors for many data analysis techniques when the size and dimensionality of data is very large. We investigate the use of Local Outlier Factor (LOF) for data of this type, providing a motivating example from real world data. We propose Projection-Indexed Nearest-Neighbours (PINN), a novel technique that exploits extended nearest neighbour sets in the a reduced dimensional space to create an accurate approximation for k-nearest-neighbour distances, which is used as the core density measurement within LOF. The reduced dimensionality allows for efficient sub-quadratic indexing in the number of items in the data set, where previously only quadratic performance was possible. A detailed theoretical analysis of Random Projection(RP) and PINN shows that we are able to preserve the density of the intrinsic manifold of the data set after projection. Experimental results show that PINN outperforms the standard projection methods RP and PCA when measuring LOF for many high-dimensional real-world data sets of up to 300000 elements and 102600 dimensions.},
	booktitle = {2010 {IEEE} {International} {Conference} on {Data} {Mining}},
	author = {Vries, T. de and Chawla, S. and Houle, M. E.},
	month = dec,
	year = {2010},
	note = {00064},
	keywords = {approximation theory, data mining, data analysis, local outlier factor, anomaly detection, Density measurement, approximation, dimensionality reduction, Euclidean distance, Indexing, k-nearest neighbour, Lighting, Object recognition, Principal component analysis, projection indexed nearest-neighbour, random processes, random projection, Scalability, set theory, subquadratic indexing},
	pages = {128--137},
	file = {IEEE Xplore Abstract Record:/home/migue/Zotero/storage/3BP8KPCE/5693966.html:text/html}
}

@inproceedings{mullerAdaptiveOutliernessSubspace2010,
	address = {New York, NY, USA},
	series = {{CIKM} '10},
	title = {Adaptive {Outlierness} for {Subspace} {Outlier} {Ranking}},
	isbn = {978-1-4503-0099-5},
	url = {http://doi.acm.org/10.1145/1871437.1871690},
	doi = {10.1145/1871437.1871690},
	abstract = {Outlier mining is an important data analysis task to distinguish exceptional outliers from regular objects. However, in recent applications traditional outlier mining approaches miss outliers as they are hidden in subspace projections. In this work, we propose a novel outlier ranking based on the degree of deviation in subspaces. Object deviation is measured only in a selection of relevant subspaces and is based on adaptive neighborhoods in these subspaces. We show that our approach outperforms competing outlier ranking approaches by detecting outliers in arbitrary subspaces.},
	urldate = {2019-06-06},
	booktitle = {Proceedings of the 19th {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}},
	publisher = {ACM},
	author = {Müller, Emmanuel and Schiffer, Matthias and Seidl, Thomas},
	year = {2010},
	note = {event-place: Toronto, ON, Canada},
	keywords = {data mining, outliers, ranking, subspaces},
	pages = {1629--1632},
	file = {2010-Müller-Adaptive_Outlierness_for_Subspace_Outlier_Ranking.pdf:/home/migue/Zotero/storage/P747RNZE/2010-Müller-Adaptive_Outlierness_for_Subspace_Outlier_Ranking.pdf:application/pdf}
}

@inproceedings{mullerStatisticalSelectionRelevant2011,
	address = {Hannover, Germany},
	title = {Statistical selection of relevant subspace projections for outlier ranking},
	isbn = {978-1-4244-8959-6},
	url = {http://ieeexplore.ieee.org/document/5767916/},
	doi = {10.1109/ICDE.2011.5767916},
	abstract = {Outlier mining is an important data analysis task to distinguish exceptional outliers from regular objects. For outlier mining in the full data space, there are well established methods which are successful in measuring the degree of deviation for outlier ranking. However, in recent applications traditional outlier mining approaches miss outliers as they are hidden in subspace projections. Especially, outlier ranking approaches measuring deviation on all available attributes miss outliers deviating from their local neighborhood only in subsets of the attributes.},
	language = {en},
	urldate = {2019-06-21},
	booktitle = {2011 {IEEE} 27th {International} {Conference} on {Data} {Engineering}},
	publisher = {IEEE},
	author = {Muller, Emmanuel and Schiffer, Matthias and Seidl, Thomas},
	month = apr,
	year = {2011},
	note = {00104},
	pages = {434--445}
}

@misc{zhaoPythonToolboxScalable2019,
	title = {A {Python} {Toolbox} for {Scalable} {Outlier} {Detection} ({Anomaly} {Detection}): yzhao062/pyod},
	copyright = {BSD-2-Clause},
	shorttitle = {A {Python} {Toolbox} for {Scalable} {Outlier} {Detection} ({Anomaly} {Detection})},
	url = {https://github.com/yzhao062/pyod},
	urldate = {2019-06-29},
	author = {Zhao, Yue},
	month = jun,
	year = {2019},
	note = {00000 
original-date: 2017-10-03T20:29:04Z}
}

@misc{APIReferenceScikitlearn,
	title = {{API} {Reference} — scikit-learn 0.21.2 documentation},
	url = {https://scikit-learn.org/stable/modules/classes.html#module-sklearn.neighbors},
	urldate = {2019-06-29},
	file = {API Reference — scikit-learn 0.21.2 documentation:/home/migue/Zotero/storage/GCGD4YYT/classes.html:text/html}
}

@article{alcala-fdezKEELSoftwareTool2009,
	title = {{KEEL}: a software tool to assess evolutionary algorithms for data mining problems},
	volume = {13},
	issn = {1432-7643, 1433-7479},
	shorttitle = {{KEEL}},
	url = {http://link.springer.com/10.1007/s00500-008-0323-y},
	doi = {10.1007/s00500-008-0323-y},
	language = {en},
	number = {3},
	urldate = {2019-06-29},
	journal = {Soft Comput},
	author = {Alcalá-Fdez, J. and Sánchez, L. and García, S. and del Jesus, M. J. and Ventura, S. and Garrell, J. M. and Otero, J. and Romero, C. and Bacardit, J. and Rivas, V. M. and Fernández, J. C. and Herrera, F.},
	month = feb,
	year = {2009},
	note = {01026},
	pages = {307--318},
	file = {2009-Alcalá-Fdez-KEEL.pdf:/home/migue/Zotero/storage/SXH94YIZ/2009-Alcalá-Fdez-KEEL.pdf:application/pdf}
}

@article{ishimtsevConformalKNNAnomaly2017,
	title = {Conformal k-{NN} {Anomaly} {Detector} for {Univariate} {Data} {Streams}},
	url = {http://arxiv.org/abs/1706.03412},
	abstract = {Anomalies in time-series data give essential and often actionable information in many applications. In this paper we consider a model-free anomaly detection method for univariate time-series which adapts to non-stationarity in the data stream and provides probabilistic abnormality scores based on the conformal prediction paradigm. Despite its simplicity the method performs on par with complex prediction-based models on the Numenta Anomaly Detection benchmark and the Yahoo! S5 dataset.},
	urldate = {2019-06-29},
	journal = {arXiv:1706.03412 [cs, stat]},
	author = {Ishimtsev, Vladislav and Nazarov, Ivan and Bernstein, Alexander and Burnaev, Evgeny},
	month = jun,
	year = {2017},
	note = {00010 
arXiv: 1706.03412},
	keywords = {Statistics - Machine Learning, Computer Science - Data Structures and Algorithms, Statistics - Applications, Statistics - Computation, Statistics - Methodology},
	file = {arXiv\:1706.03412 PDF:/home/migue/Zotero/storage/LA22ILBS/Ishimtsev et al. - 2017 - Conformal k-NN Anomaly Detector for Univariate Dat.pdf:application/pdf;arXiv.org Snapshot:/home/migue/Zotero/storage/FJ9DVNE9/1706.html:text/html}
}

@misc{quotationsEugeneNathanielButler,
	title = {Eugene {Nathaniel} {Butler} {Quotes}, {Quotations} \& {Sayings} 2019},
	url = {http://www.searchquotes.com/search/Eugene_Nathaniel_Butler/4/},
	abstract = {Eugene Nathaniel Butler quotes - Read more quotes and sayings about Eugene Nathaniel Butler.},
	urldate = {2019-06-30},
	journal = {Search Quotes},
	author = {Quotations, SearchQuotes com},
	file = {Snapshot:/home/migue/Zotero/storage/C7UVTJWI/4.html:text/html}
}

@article{jabezIntrusionDetectionSystem2015,
	title = {Intrusion {Detection} {System} ({IDS}): {Anomaly} {Detection} {Using} {Outlier} {Detection} {Approach}},
	volume = {48},
	shorttitle = {Intrusion {Detection} {System} ({IDS})},
	doi = {10.1016/j.procs.2015.04.191},
	abstract = {An Intrusion Detection System (IDS) is a software application or device that monitors the system or activities of network for policy violations or malicious activities and generates reports to the management system. A number of systems may try to prevent an intrusion attempt but this is neither required nor expected of a monitoring system. The main focus of Intrusion detection and prevention systems (IDPS) is to identify the possible incidents, logging information about them and in report attempts. In addition, organizations use IDPS for other purposes, like identifying problems with security policies, deterring individuals and documenting existing threats from infringing security policies. IDPS have become an essential addition to the security infrastructure of nearly every organization. Various methods can be used to detect intrusions but each one is specific to a specific method. The main goal of an intrusion detection system is to detect the attacks efficiently. Furthermore, it is equally important to detect attacks at a beginning stage in order to reduce their impacts. This research work proposed a new approach called outlier detection where, the anomaly dataset is measured by the Neighborhood Outlier Factor (NOF). Here, trained model consists of big datasets with distributed storage environment for improving the performance of Intrusion Detection system. The experimental results proved that the proposed approach identifies the anomalies very effectively than any other approaches.},
	journal = {Procedia Computer Science},
	author = {Jabez, J and Muthukumar, B},
	month = dec,
	year = {2015},
	note = {00050},
	pages = {338--346},
	file = {2015-Jabez-Intrusion_Detection_System_(IDS).pdf:/home/migue/Zotero/storage/NNNDQ9NH/2015-Jabez-Intrusion_Detection_System_(IDS).pdf:application/pdf}
}

@inproceedings{kumarAnomalyBasedNetworkIntrusion2019,
	title = {Anomaly-{Based} {Network} {Intrusion} {Detection}: {An} {Outlier} {Detection} {Techniques}},
	shorttitle = {Anomaly-{Based} {Network} {Intrusion} {Detection}},
	doi = {10.1007/978-3-319-60618-7_26},
	abstract = {A robust Network Intrusion Detection System (NIDS) has become the need of today’s era. To provide a robust mechanism require to distinguish between normal and anomalous activities, outliers detection with the help of data mining, play an important role in detection and distinction of such activities in the midst of enhanced performance in detection of false alarm. Now day’s researchers focus on applying outlier detection techniques for anomaly detection because of its promising results in discover true attacks and in sinking false alarm rate. So this paper contributed a enhanced mechanism of outlier detection to enhance accuracy in intrusion detection by introducing Density based Outlier detection into Data Mining using Hamming Densities of a data point. Hamming density is k-nearest neighbour divided by Hamming-distance. Analyzed the outcomes of our proposed by doing experiment using UCI repository KDD Cup’99 Intrusion data-set on our simulator work and compare the result with other such existing algorithms like LOF, LOF′ and found more accuracy and increase in detecting the number of true positive alarm in our proposed work.},
	author = {Kumar, Neeraj and Kumar, Upendra},
	month = mar,
	year = {2019},
	note = {00002},
	file = {Full Text PDF:/home/migue/Zotero/storage/7KGW9DU9/Kumar y Kumar - 2019 - Anomaly-Based Network Intrusion Detection An Outl.pdf:application/pdf}
}

@article{vIdentificationOutliersMedical2014,
	title = {Identification of {Outliers} in {Medical} {Diagnostic} {System} {Using} {Data} {Mining} {Techniques}},
	volume = {2014},
	doi = {10.5923/j.statistics.20140406.01},
	abstract = {The outlier detection problem has important applications in the field of medical research. Clinical databases have accumulated large quantities of information about patients and their medical conditions. In this study, the data mining techniques are used to search for relationships in a large clinical database. Relationships and patterns within this data could provide new medical knowledge. The main objective of this paper is to detect the outliers and identify the influence factor in the diabetes symptoms of the patient using data mining techniques. Results are illustrated numerically and graphically.},
	author = {V, Deneshkumar and Kaliyaperumal, Senthamarai and Mani, Manikandan},
	month = jun,
	year = {2014},
	note = {00014},
	pages = {241--248},
	file = {Full Text PDF:/home/migue/Zotero/storage/WVHFBHW4/V et al. - 2014 - Identification of Outliers in Medical Diagnostic S.pdf:application/pdf}
}

@inproceedings{gasparSystematicReviewOutliers2011,
	title = {A {Systematic} {Review} of {Outliers} {Detection} {Techniques} in {Medical} {Data} - {Preliminary} {Study}},
	abstract = {Background: Patient medical records contain many entries relating to patient conditions, treatments and lab results. Generally involve multiple types of data and produces a large amount of information. These databases can provide important information for clinical decision and to support the management of the hospital. Medical databases have some specificities not often found in others non-medical databases. In this context, outlier detection techniques can be used to detect abnormal patterns in health records (for instance, problems in data quality) and this contributing to better data and better knowledge in the process of decision},
	booktitle = {{HEALTHINF}},
	author = {Gaspar, Juliano de Souza and Catumbela, Emanuel and Marques, Bernardo and Freitas, Alberto},
	year = {2011},
	note = {00003},
	keywords = {Data mining, Cluster analysis, Bibliographic database, Data quality, Database, Freedom of information laws by country, MEDLINE, OR gate, Systematic review},
	file = {Full Text PDF:/home/migue/Zotero/storage/45UBBQAV/Gaspar et al. - 2011 - A Systematic Review of Outliers Detection Techniqu.pdf:application/pdf}
}

@article{porwalCreditCardFraud2018,
	title = {Credit {Card} {Fraud} {Detection} in e-{Commerce}: {An} {Outlier} {Detection} {Approach}},
	shorttitle = {Credit {Card} {Fraud} {Detection} in e-{Commerce}},
	url = {http://arxiv.org/abs/1811.02196},
	abstract = {Often the challenge associated with tasks like fraud and spam detection is the lack of all likely patterns needed to train suitable supervised learning models. This problem accentuates when the fraudulent patterns are not only scarce, they also change over time. Change in fraudulent pattern is because fraudsters continue to innovate novel ways to circumvent measures put in place to prevent fraud. Limited data and continuously changing patterns makes learning significantly difficult. We hypothesize that good behavior does not change with time and data points representing good behavior have consistent spatial signature under different groupings. Based on this hypothesis we are proposing an approach that detects outliers in large data sets by assigning a consistency score to each data point using an ensemble of clustering methods. Our main contribution is proposing a novel method that can detect outliers in large datasets and is robust to changing patterns. We also argue that area under the ROC curve, although a commonly used metric to evaluate outlier detection methods is not the right metric. Since outlier detection problems have a skewed distribution of classes, precision-recall curves are better suited because precision compares false positives to true positives (outliers) rather than true negatives (inliers) and therefore is not affected by the problem of class imbalance. We show empirically that area under the precision-recall curve is a better than ROC as an evaluation metric. The proposed approach is tested on the modified version of the Landsat satellite dataset, the modified version of the ann-thyroid dataset and a large real world credit card fraud detection dataset available through Kaggle where we show significant improvement over the baseline methods.},
	urldate = {2019-06-30},
	journal = {arXiv:1811.02196 [cs, stat]},
	author = {Porwal, Utkarsh and Mukund, Smruthi},
	month = nov,
	year = {2018},
	note = {00000 
arXiv: 1811.02196},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv\:1811.02196 PDF:/home/migue/Zotero/storage/3XIEWCQV/Porwal y Mukund - 2018 - Credit Card Fraud Detection in e-Commerce An Outl.pdf:application/pdf;arXiv.org Snapshot:/home/migue/Zotero/storage/VYW4LNYQ/1811.html:text/html}
}

@article{amrutad.pawarSurveyOutlierDetection2014,
	title = {A {Survey} on {Outlier} {Detection} {Techniques} for {Credit} {Card} {Fraud} {Detection}},
	volume = {16},
	doi = {10.9790/0661-16264448},
	journal = {IOSR Journal of Computer Engineering},
	author = {Amruta D. Pawar, Ms and Prakash N. Kalavadekar, Prof and Swapnali N. Tambe, Ms},
	month = jan,
	year = {2014},
	note = {00013},
	pages = {44--48},
	file = {Texto completo:/home/migue/Zotero/storage/XJEY5N8W/Amruta D. Pawar et al. - 2014 - A Survey on Outlier Detection Techniques for Credi.pdf:application/pdf}
}

@misc{Miki97TFGOutlierDetectionHttps,
	title = {miki97/{TFG}-{OutlierDetection} https://github.com/miki97/{TFG}-{OutlierDetection}},
	url = {https://github.com/miki97/TFG-OutlierDetection},
	abstract = {Implementación de algoritmos para detección de anomalías, basados en proximidad - miki97/TFG-OutlierDetection},
	language = {en},
	urldate = {2019-08-16},
	journal = {GitHub},
	file = {Snapshot:/home/migue/Zotero/storage/3FMYYUVF/TFG-OutlierDetection.html:text/html}
}

@misc{PyDBODDistancesBased,
	title = {{PyDBOD}: {A} {Distances} {Based} {Outlier} {Detector} package https://pypi.org/project/{PyDBOD}/},
	copyright = {Licencia pública general de GNU Versión 3},
	shorttitle = {{PyDBOD}},
	url = {https://pypi.org/project/PyDBOD/},
	urldate = {2019-08-28},
	file = {Snapshot:/home/migue/Zotero/storage/4E36Q3TY/PyDBOD.html:text/html}
}